{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Jo√£o Gabriel Valentim Rocha\n",
    "\n",
    "Nome: Enzo Dadier Lacks Zamberlan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn\n",
    "#!pip install emoji\n",
    "#!pip install pysinonimos\n",
    "#!pip install nltk\n",
    "#!pip install sklearn\n",
    "#!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import nltk\n",
    "import pysinonimos.sinonimos as sinom\n",
    "from emoji import UNICODE_EMOJI\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\gabri\\Desktop\\Mat√©rias 2 semestre\\cdados\\P1\\Classificador_automatico_de_sentimentos\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'assets/loki.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mood de hj: bolsominion veio falar com loki:\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdds do loki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>considera√ß√µes finais de loki: parab√©ns marvel,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_namizinhaa @yaluv_ @_girlrainbow vers√£o femi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o loki merece todo o amor do mundo ? \\n \\n  si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>o loki tbm ? percebi que nao sei mais nada sob...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>t√¥ desde as 9 fazendo atividade e o loki destr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@torystyliinson @mobiusdaavt pede pra ele te m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>bolsonaro t√° desesperado. discurso inflado, go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>vou terminar loki hj, espero n√£o me decepcionar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia\n",
       "0    mood de hj: bolsominion veio falar com loki:\\n...           0\n",
       "1                                         sdds do loki           1\n",
       "2    considera√ß√µes finais de loki: parab√©ns marvel,...           1\n",
       "3    @_namizinhaa @yaluv_ @_girlrainbow vers√£o femi...           0\n",
       "4    o loki merece todo o amor do mundo ? \\n \\n  si...           1\n",
       "..                                                 ...         ...\n",
       "295  o loki tbm ? percebi que nao sei mais nada sob...           1\n",
       "296  t√¥ desde as 9 fazendo atividade e o loki destr...           0\n",
       "297  @torystyliinson @mobiusdaavt pede pra ele te m...           0\n",
       "298  bolsonaro t√° desesperado. discurso inflado, go...           0\n",
       "299    vou terminar loki hj, espero n√£o me decepcionar           1\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comecei loki e logo no primeiro epis√≥dio ele s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@thylaspirk exatamente \\nn√£o d√° cara loki mere...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pq a marvel falou que loki √© irm√£o se thor sen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vou fazer com o loki ü•∞ü§£ https://t.co/qry6pytktj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@stawocon loki eu ainda vi dnv ksksksksksksksk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>vou fazer uma x√≠cara tem√°tica pra mim, mas t√¥ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>o primeiro dente de leite de loki caiu https:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>@mobiusdaavt @loki_l4ufeys0n eu vou te bloquear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>queria ter juntado uma semana de merda de loki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>como a po$$@ de um tanque de guerra de cerveja...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevancia\n",
       "0    comecei loki e logo no primeiro epis√≥dio ele s...           1\n",
       "1    @thylaspirk exatamente \\nn√£o d√° cara loki mere...           1\n",
       "2    pq a marvel falou que loki √© irm√£o se thor sen...           0\n",
       "3      vou fazer com o loki ü•∞ü§£ https://t.co/qry6pytktj           1\n",
       "4    @stawocon loki eu ainda vi dnv ksksksksksksksk...           1\n",
       "..                                                 ...         ...\n",
       "195  vou fazer uma x√≠cara tem√°tica pra mim, mas t√¥ ...           0\n",
       "196  o primeiro dente de leite de loki caiu https:/...           0\n",
       "197    @mobiusdaavt @loki_l4ufeys0n eu vou te bloquear           0\n",
       "198  queria ter juntado uma semana de merda de loki...           0\n",
       "199  como a po$$@ de um tanque de guerra de cerveja...           0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O classificador autom√°tico de sentimentos montado tem como crit√©rio utilizado a relev√¢ncia de tweets que remetam a alguma rea√ß√£o ou la√ßo sentimental em rela√ß√£o √† s√©rie, sendo os mesmos positivos ou n√£o (elogiando algum epis√≥dio, comentando valores da s√©rie, ou ainda, criticando os mesmos). Neste sentido, postagens que dizem respeito unicamente a aspectos nesse tocante, elogiando ou comentando sobre os atores da obra, como tamb√©m tweets com vagas men√ß√µes sobre a s√©rie, foram considerados como irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimentos e configura√ß√µes iniciais\n",
    "\n",
    "Para continuarmos, √© necess√°rio definir algumas fun√ß√µes b√°sicas que v√£o nos ajudar:\n",
    "\n",
    "1) Primeiro, vamos fazer a limpeza dos tweets. Retirando simbolos e pontua√ß√µes que n√£o ser√£o contabilizadas para nossa an√°lise\n",
    "\n",
    "2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 0\n",
    "def separa_emoji(tweet):\n",
    "    # Essa fun√ß√£o separa os emojis e transcreve suas respectivas descri√ß√µes\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\n",
    "    modified=modified.split()\n",
    "    for i,emoji1 in enumerate(modified):\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\n",
    "        else:\n",
    "            continue\n",
    "    modified=' '.join(modified)\n",
    "        \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1\n",
    "def limpa_frase(frase):\n",
    "    # Primeiro, poe todas as palavras com letras min√∫sculas\n",
    "    aux = frase.lower()\n",
    "    \n",
    "    # Segundo, remove # and @\n",
    "    aux = re.sub(\"@[A-Za-z0-9_]+\",\"\", aux)\n",
    "    aux = re.sub(\"#[A-Za-z0-9_]+\",\"\", aux)\n",
    "    \n",
    "    # Terceiro, remove links\n",
    "    aux = re.sub(r\"http\\S+\", \"\", aux)\n",
    "    aux = re.sub(r\"www.\\S+\", \"\", aux)\n",
    "    \n",
    "    # Quarto, remove pontua√ß√£o\n",
    "    aux = re.sub('[()!?]', ' ', aux)\n",
    "    aux = re.sub('\\[.*?\\]',' ', aux)\n",
    "    \n",
    "    # Quinto, separa e troca os emojis pela sua respectiva descri√ß√£o\n",
    "    aux = separa_emoji(aux)\n",
    "    aux = aux.replace(\"_\", \"\")\n",
    "    \n",
    "    # Sexto, remove acentos\n",
    "    aux = unidecode.unidecode(aux)\n",
    "    \n",
    "    # S√©timo, remove n√£o alfa-numericos\n",
    "    aux = re.sub(\"[^a-z0-9]\",\" \", aux)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2\n",
    "# transforma uma string em uma lista, de tal forma que √© poss√≠vel acessar palavra por palavra\n",
    "def tokenize(frase):\n",
    "    return frase.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Passo 3\n",
    "# Aqui ser√£o contabilizadas as \"stop words\"\n",
    "nltk.download('stopwords')\n",
    "prep = nltk.corpus.stopwords.words('portuguese')\n",
    "prep.append('')\n",
    "prep = prep + ['n', 's']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4\n",
    "# Essa fun√ß√£o retira as stop words de uma lista tokenizada\n",
    "def no_stop_words(token):\n",
    "    clear = []\n",
    "    for element in token:\n",
    "        if element not in prep:\n",
    "            clear.append(element)\n",
    "    return clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar para transformar de lista para string\n",
    "def list_to_string(lista):\n",
    "    return ' '.join(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o final que limpa todo tweet e devolve em formato de string\n",
    "def limpa_tweet(tweet):\n",
    "    return list_to_string(no_stop_words(tokenize(limpa_frase(tweet))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera uma pd.Series do set_frases\n",
    "def frases_to_series(set_frases):\n",
    "    set_frases += ' '\n",
    "    return pd.Series(tokenize(set_frases.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"aux = train['Clean']\\nprint(len(frases_to_series(aux)), len(frases_to_series_2(aux)))\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''aux = train['Clean']\n",
    "print(len(frases_to_series(aux)), len(frases_to_series_2(aux)))'''\n",
    "#frases_to_series_2(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando palavras em vari√°veis categ√≥ricas\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando fun√ß√µes de limpeza e certifica√ß√£o no dataframe de treinamento da base de dados\n",
    "train['Clean'] = train['Treinamento'].apply(limpa_tweet)\n",
    "test['Clean'] = test['Teste'].apply(limpa_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os tweets relevantes dos irrelevantes\n",
    "train_rel = train[train['Relevancia'] == 1]\n",
    "train_irrel= train[train['Relevancia'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera uma pd.Series das palavras relevantes e irrelevantes do training set\n",
    "palavras_rel = frases_to_series(train_rel['Clean'])\n",
    "palavras_irrel = frases_to_series(train_irrel['Clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera duas listas com as palavras relevantes e irrelevantes e gera uma lista total\n",
    "lista_palavras_rel = list(palavras_rel)\n",
    "lista_palavras_irrel = list(palavras_irrel)\n",
    "lista_palavras = lista_palavras_rel + lista_palavras_irrel\n",
    "lista_palavras_sem_repeticao = list(set(lista_palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera um pd.Series da lista com todas as palavras\n",
    "palavras = pd.Series(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencias relativas\n",
    "freq_palavras_relevantes = palavras_rel.value_counts(True)\n",
    "freq_palavras_irrelevantes = palavras_irrel.value_counts(True)\n",
    "freq_palavras_total = palavras.value_counts(True)\n",
    "\n",
    "# Frequencias absolutas\n",
    "freq_palavras_relevantes_abs = palavras_rel.value_counts()\n",
    "freq_palavras_irrelevantes_abs = palavras_irrel.value_counts()\n",
    "freq_palavras_total_abs = palavras.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades \n",
    "\n",
    "Aqui abordaremos os valores das probabilidades que ser√£o imprescind√≠veis para a constru√ß√£o do modelo. Em primeiro lugar, note que as probabilidade de serem relevantes ou serem irrelevantes podem ser expressas da seguinte forma:\n",
    " \n",
    " * $P(R) \\rightarrow $  Probabilidade de ser relevante\n",
    " * $P(I)=P(R^c) \\rightarrow $  Probabilidade de ser irrelevante\n",
    " \n",
    "Al√©m disso, por serem complementares, temos que: $P(R) + P(I) = P(R) + P(R^c) = 1$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando a raz√£o entre a quantidade de palavras da lista de relevantes pelo n√∫mero total, temos P_R\n",
    "P_R = len(lista_palavras_rel) / len(lista_palavras)\n",
    "\n",
    "# Por complementar, temos P_Rc\n",
    "P_Rc = 1 - P_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades Condicionais e o Teorema de Bayes\n",
    "Temos que, para o c√°lculo de probabilidades condicionais, fazemos uso da seguinte rela√ß√£o:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "Onde, \n",
    "* $P(A|B) \\rightarrow $ Probabilidade de A ocorrer, dado que B ocorreu  \n",
    "* $P(A \\cap B) \\rightarrow $ Probabilidade de A ocorrer e B ocorrer\n",
    "* $P(B) \\rightarrow $ Probabilidade de B ocorrer\n",
    "\n",
    "Analogamente, temos que:\n",
    "$$P(B|A) = \\frac{P(B \\cap A)}{P(A)}$$\n",
    "\n",
    "Onde, \n",
    "* $P(B|A) \\rightarrow $ Probabilidade de A ocorrer, dado que B ocorreu  \n",
    "* $P(B \\cap A) \\rightarrow $ Probabilidade de B ocorrer e A ocorrer\n",
    "* $P(A) \\rightarrow $ Probabilidade de B ocorrer\n",
    "\n",
    "Note que as probabilidades da interse√ß√£o podem comutar os eventos A e B, portanto: $P(B \\cap A) = P(A \\cap B)$\n",
    "\n",
    "Dessa forma, podemos extrair o conhecido Teorema de Bayes:\n",
    "\n",
    "$$P(A|B) = P(B|A).\\frac{P(A)}{P(B)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Classificador de Naive Bayes\n",
    "\n",
    "O Classificador de Naive Bayes se baseia na constru√ß√£o de um modelo bag-of-word. Na an√°lise de sentimento, queremos responder a seguinte pergunta: \"Qual a probabilidade dessa frase ser relevante, dado esse conjunto de palavras?\". Nesse sentido, √© necess√°rio computar esse c√°lculo utilizando probabilidades condicionais e o resultado do teorema de Bayes encontrado na sess√£o anterior:\n",
    "\n",
    "$$P(R|frase) = \\frac{P(frase|R).P(R)}{P(frase)}$$\n",
    "\n",
    "Dessa forma, n√≥s vamos usar essa rela√ß√£o para encontrar $P(R|frase)$, ou seja, a probabilidade de uma frase ser relevante, dado o conjunto de palavras. Para tanto, tome como exemplo a frase: \"meu av√¥ ama isso\", em termos de nota√ß√£o, queremos encontrar:\n",
    "\n",
    "$$P(R|\"meu avo ama isso\") = \\frac{P(\"meu avo ama isso\"|R).P(R)}{P(\"meu avo ama isso\")}$$\n",
    "\n",
    "Para prosseguir, utilizaremos um processo de \"Tokeniza√ß√£o\", que consiste em dividir a frase em peda√ßos menores (as palavras) e assumir que uma palavra n√£o influencia na coloca√ß√£o da outra. Sabemos que isso n√£o √© verdade, mas utilizaremos por quest√µes de simplifica√ß√£o (essa √© a ingenuidade do classificador de Naive Bayes). Portanto, nosso c√°lculo ficara da seguinte forma:\n",
    "\n",
    "$$P(\"meuavoamaisso\"|R) = P(\"meu\"|R).P(\"av√¥\"|R).P(\"ama\"|R).P(\"isso\"|R)$$\n",
    "\n",
    "Logo, nossa express√£o final ser√°:\n",
    "\n",
    "$$P(R|\"meu avo ama isso\") = \\frac{P(\"meu\"|R).P(\"av√¥\"|R).P(\"ama\"|R).P(\"isso\"|R).P(R)}{P(\"meu avo ama isso\")}$$\n",
    "\n",
    "Analogamente, para encontrarmos a probabilidade dele ser irrelevante, podemos fazer o mesmo c√°lculo:\n",
    "\n",
    "$$P(I|\"meu avo ama isso\") = \\frac{P(\"meu\"|I).P(\"av√¥\"|I).P(\"ama\"|I).P(\"isso\"|I).P(I)}{P(\"meu avo ama isso\")}$$\n",
    "\n",
    "Agora, basta compararmos os valores das probabilidades:\n",
    "\n",
    "Se, $P(R|\"meu avo ama isso\") > P(I|\"meu avo ama isso\")$, ent√£o, √© mais prov√°vel que a frase seja $relevante$\n",
    "\n",
    "\n",
    "Caso contr√°rio, $P(R|\"meu avo ama isso\") < P(I|\"meu avo ama isso\")$, ent√£o, √© mais prov√°vel que a frase seja $irrelevante$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suaviza√ß√£o de Laplace\n",
    "\n",
    "√â importante ressaltar que para o caso de uma determina palavra em uma frase n√£o pertencer ao nosso conjunto universo, a probabilidade atribuida a essa palavra ser√° zero. Por√©m, n√£o podemos utilizar a probabilidade de 0 por raz√µes alg√©bricas, portanto, utilizaremos a <b><em>Suaviza√ß√£o de Laplace</em></b>. Basicamente essa ferramenta ir√° nos ajudar a inserir a palavra \"estranha\" no quesito probabil√≠stico das categorias discutidas.\n",
    "\n",
    "$$P(palavra|W) = \\frac{F_{AW}+1}{P_{W}+P_{W^c}}$$\n",
    "\n",
    "Onde: \n",
    "\n",
    "$ F_{AW} \\rightarrow$ Frequ√™ncia absoluta da palavra na categoria W\n",
    "    \n",
    "$P_{W} \\rightarrow$ Todas as palavras pertencentes √†s frases rotuladas como da categoria W\n",
    "    \n",
    "$P_{W^c} \\rightarrow$ Todas as palavras pertencentes √†s frases rotuladas como da categoria W^c\n",
    "\n",
    "Nesse sentido, tome $W$ como sendo o evento $R$ e $W^c$ como sendo o evento $I$ ou $R^C$. Dessa forma, a soma do valor 1 faz com que o nosso resultado de $P(R|frase)$ ou $P(I|frase)$ nunca se torne zero, mesmo que a frequ√™ncia absoluta da palavra seja zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A suaviza√ß√£o de Laplace ser√° utilizada para os casos em que uma determinada palavra da frase n√£o se encontra \n",
    "no conjunto universo.\n",
    "'''\n",
    "def suavizacao_de_laplace(palavra, relevancia, freq_palavras_abs):\n",
    "    try:\n",
    "        FAW = freq_palavras_abs[palavra]\n",
    "    except:\n",
    "        FAW = 0\n",
    "    if relevancia == 'R':\n",
    "        return (FAW + 1) / (len(lista_palavras_rel) + len(lista_palavras_sem_repeticao))\n",
    "    elif relevancia == 'I' or relevancia == 'Rc':\n",
    "        return (FAW + 1) / (len(lista_palavras_irrel) + len(lista_palavras_sem_repeticao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o que calcula a probabilidade que queremos para fazer a desigualdade e decidir a categoria mais prov√°vel\n",
    "def P(relevancia, frase):\n",
    "    if type(frase) != list:\n",
    "        frase = tokenize(frase)\n",
    "    if relevancia == 'R':\n",
    "        P_F_dado_R = 1\n",
    "        for palavra in frase:\n",
    "            P_F_dado_R *= suavizacao_de_laplace(palavra, relevancia, freq_palavras_relevantes_abs)\n",
    "        P_R_dado_F = P_F_dado_R * P_R\n",
    "        return P_R_dado_F\n",
    "            \n",
    "    elif relevancia == 'I' or relevancia == 'Rc':\n",
    "        P_F_dado_Rc = 1\n",
    "        for palavra in frase:\n",
    "            P_F_dado_Rc *= suavizacao_de_laplace(palavra, relevancia, freq_palavras_irrelevantes_abs)\n",
    "        P_Rc_dado_F = P_F_dado_Rc * P_Rc\n",
    "        return P_Rc_dado_F\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o final que recorre ao modelo de Naive Bayes\n",
    "def NaiveBayesModel(frase):\n",
    "    if P('R', frase) > P('I', frase):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = test.copy()\n",
    "aux['Modelo'] = aux['Clean'].apply(NaiveBayesModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    111\n",
       "1     89\n",
       "Name: Modelo, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.Modelo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    132\n",
       "1     68\n",
       "Name: Relevancia, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.Relevancia.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mood de hj: bolsominion veio falar com loki:\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>mood hj bolsominion veio falar loki nao loki b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdds do loki</td>\n",
       "      <td>1</td>\n",
       "      <td>sdds loki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>considera√ß√µes finais de loki: parab√©ns marvel,...</td>\n",
       "      <td>1</td>\n",
       "      <td>consideracoes finais loki parabens marvel chor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_namizinhaa @yaluv_ @_girlrainbow vers√£o femi...</td>\n",
       "      <td>0</td>\n",
       "      <td>versao feminina loki multiverso</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o loki merece todo o amor do mundo ? \\n \\n  si...</td>\n",
       "      <td>1</td>\n",
       "      <td>loki merece todo amor mundo sim sim sim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>o loki tbm ? percebi que nao sei mais nada sob...</td>\n",
       "      <td>1</td>\n",
       "      <td>loki tbm percebi nao sei nada sobre mcu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>t√¥ desde as 9 fazendo atividade e o loki destr...</td>\n",
       "      <td>0</td>\n",
       "      <td>to desde 9 fazendo atividade loki destruiu gen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@torystyliinson @mobiusdaavt pede pra ele te m...</td>\n",
       "      <td>0</td>\n",
       "      <td>pede pra mandar pix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>bolsonaro t√° desesperado. discurso inflado, go...</td>\n",
       "      <td>0</td>\n",
       "      <td>bolsonaro ta desesperado discurso inflado golp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>vou terminar loki hj, espero n√£o me decepcionar</td>\n",
       "      <td>1</td>\n",
       "      <td>vou terminar loki hj espero nao decepcionar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia  \\\n",
       "0    mood de hj: bolsominion veio falar com loki:\\n...           0   \n",
       "1                                         sdds do loki           1   \n",
       "2    considera√ß√µes finais de loki: parab√©ns marvel,...           1   \n",
       "3    @_namizinhaa @yaluv_ @_girlrainbow vers√£o femi...           0   \n",
       "4    o loki merece todo o amor do mundo ? \\n \\n  si...           1   \n",
       "..                                                 ...         ...   \n",
       "295  o loki tbm ? percebi que nao sei mais nada sob...           1   \n",
       "296  t√¥ desde as 9 fazendo atividade e o loki destr...           0   \n",
       "297  @torystyliinson @mobiusdaavt pede pra ele te m...           0   \n",
       "298  bolsonaro t√° desesperado. discurso inflado, go...           0   \n",
       "299    vou terminar loki hj, espero n√£o me decepcionar           1   \n",
       "\n",
       "                                                 Clean  Modelo  \n",
       "0    mood hj bolsominion veio falar loki nao loki b...       0  \n",
       "1                                            sdds loki       1  \n",
       "2    consideracoes finais loki parabens marvel chor...       1  \n",
       "3                      versao feminina loki multiverso       0  \n",
       "4              loki merece todo amor mundo sim sim sim       1  \n",
       "..                                                 ...     ...  \n",
       "295            loki tbm percebi nao sei nada sobre mcu       0  \n",
       "296  to desde 9 fazendo atividade loki destruiu gen...       0  \n",
       "297                                pede pra mandar pix       0  \n",
       "298  bolsonaro ta desesperado discurso inflado golp...       0  \n",
       "299        vou terminar loki hj espero nao decepcionar       1  \n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
