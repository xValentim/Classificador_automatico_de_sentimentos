{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: João Gabriel Valentim Rocha\n",
    "\n",
    "Nome: Enzo Dadier Lacks Zamberlan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn\n",
    "#!pip install emoji\n",
    "#!pip install pysinonimos\n",
    "#!pip install nltk\n",
    "#!pip install sklearn\n",
    "#!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import seaborn as sn\n",
    "from nltk import SnowballStemmer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import nltk\n",
    "import pysinonimos.sinonimos as sinom\n",
    "from emoji import UNICODE_EMOJI\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Lenovo\\CIÊNCIA_DE_DADOS\\Classificador_de_sentimentos\\Espero_que_seja_o_ultimo\\Classificador_automatico_de_sentimentos-1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'assets/Loki_aleatório.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@agtha_harkness @mobiusdaavt @pooldeangostoso ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@chiidenoir amg esquece\\nela shippa thor e loki</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a menina falando mal de loki puta que pariu se...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@octavio_guedes a técnica para dar volume: ao ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@loki__mugo fuliza inanidai ata</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>@clintarqueiro @bracinhodeferro @meupai_eadory...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>eu fico toda coisada pelo loki</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>@sylvielaufeydit @bracinhodeferro @meupai_eado...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>@kookvlong pode</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>amo a epifania q estou tendo com loki pq acho ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia\n",
       "0    @agtha_harkness @mobiusdaavt @pooldeangostoso ...         0.0\n",
       "1      @chiidenoir amg esquece\\nela shippa thor e loki         1.0\n",
       "2    a menina falando mal de loki puta que pariu se...         1.0\n",
       "3    @octavio_guedes a técnica para dar volume: ao ...         0.0\n",
       "4                      @loki__mugo fuliza inanidai ata         0.0\n",
       "..                                                 ...         ...\n",
       "793  @clintarqueiro @bracinhodeferro @meupai_eadory...         0.0\n",
       "794                     eu fico toda coisada pelo loki         1.0\n",
       "795  @sylvielaufeydit @bracinhodeferro @meupai_eado...         0.0\n",
       "796                                    @kookvlong pode         0.0\n",
       "797  amo a epifania q estou tendo com loki pq acho ...         1.0\n",
       "\n",
       "[798 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demorou mas finalmente tô assistindo loki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@benuron_ @beatriz__asf xiu nao quero saber de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ᅟᅟ\\n\\neu e a tia sylvie atormentando o tio lok...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vote 24 pra eleger loki como presidente em 202...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indo de descer com o loki e mimir</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>honestamente esperava mais do twitter, fiquei ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>pq ninguém está falando sobre a agatha de wand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>@datrueee @mao77sem @dvszinx9 @kayky9rs @wtfsn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>vo terminar de ver loki, depois vou ver o film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>meu deus kkkkkkkkkkkkk a temporada de loki foi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevancia\n",
       "0            demorou mas finalmente tô assistindo loki           1\n",
       "1    @benuron_ @beatriz__asf xiu nao quero saber de...           0\n",
       "2    ᅟᅟ\\n\\neu e a tia sylvie atormentando o tio lok...           1\n",
       "3    vote 24 pra eleger loki como presidente em 202...           1\n",
       "4                    indo de descer com o loki e mimir           0\n",
       "..                                                 ...         ...\n",
       "196  honestamente esperava mais do twitter, fiquei ...           0\n",
       "197  pq ninguém está falando sobre a agatha de wand...           1\n",
       "198  @datrueee @mao77sem @dvszinx9 @kayky9rs @wtfsn...           0\n",
       "199  vo terminar de ver loki, depois vou ver o film...           0\n",
       "200  meu deus kkkkkkkkkkkkk a temporada de loki foi...           1\n",
       "\n",
       "[201 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O classificador automático de sentimentos montado tem como critério utilizado a relevância de tweets que remetam a alguma reação ou laço sentimental em relação à série, sendo os mesmos positivos ou não (elogiando algum episódio, comentando valores da série, ou ainda, criticando os mesmos). Neste sentido, postagens que dizem respeito unicamente a aspectos nesse tocante, elogiando ou comentando sobre os atores da obra, como também tweets com vagas menções sobre a série, foram considerados como irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimentos e configurações iniciais\n",
    "\n",
    "Para continuarmos, é necessário definir algumas funções básicas que vão nos ajudar:\n",
    "\n",
    "1) Primeiro, vamos fazer a limpeza dos tweets. Retirando simbolos e pontuações que não serão contabilizadas para nossa análise\n",
    "\n",
    "2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 0\n",
    "def separa_emoji(tweet):\n",
    "    # Essa função separa os emojis e transcreve suas respectivas descrições\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\n",
    "    modified=modified.split()\n",
    "    for i,emoji1 in enumerate(modified):\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\n",
    "        else:\n",
    "            continue\n",
    "    modified=' '.join(modified)\n",
    "        \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1\n",
    "stemmer = SnowballStemmer('portuguese')\n",
    "def limpa_frase(frase):\n",
    "    # Primeiro, poe todas as palavras com letras minúsculas\n",
    "    aux = frase.lower()\n",
    "    \n",
    "    # Segundo, remove # and @\n",
    "    aux = re.sub(\"@[A-Za-z0-9_]+\",\"\", aux)\n",
    "    aux = re.sub(\"#[A-Za-z0-9_]+\",\"\", aux)\n",
    "    \n",
    "    # Terceiro, remove links\n",
    "    aux = re.sub(r\"http\\S+\", \"\", aux)\n",
    "    aux = re.sub(r\"www.\\S+\", \"\", aux)\n",
    "    \n",
    "    # Quarto, remove pontuação\n",
    "    aux = re.sub('[()!?]', ' ', aux)\n",
    "    aux = re.sub('\\[.*?\\]',' ', aux)\n",
    "    \n",
    "    # Quinto, separa e troca os emojis pela sua respectiva descrição\n",
    "    aux = separa_emoji(aux)\n",
    "    aux = aux.replace(\"_\", \"\")\n",
    "    \n",
    "    # Sexto, remove acentos\n",
    "    aux = unidecode.unidecode(aux)\n",
    "    \n",
    "    # Sétimo, remove não alfa-numericos\n",
    "    aux = re.sub(\"[^a-z0-9]\",\" \", aux)\n",
    "    \n",
    "    # Oitavo, aplica Stemming\n",
    "    aux_2 = ''\n",
    "    lista_das_palavras = aux.split()\n",
    "    for palavra in lista_das_palavras:\n",
    "        nova_palavra = stemmer.stem(palavra)\n",
    "        aux_2 += nova_palavra + ' '\n",
    "    aux = aux_2.rstrip()\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2\n",
    "# transforma uma string em uma lista, de tal forma que é possível acessar palavra por palavra\n",
    "def tokenize(frase):\n",
    "    return frase.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Passo 3\n",
    "# Aqui serão contabilizadas as \"stop words\"\n",
    "nltk.download('stopwords')\n",
    "prep = nltk.corpus.stopwords.words('portuguese')\n",
    "prep.append('')\n",
    "prep = prep + ['n', 's', 'pq', 'q', 'to', 'pra', 'ja']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4\n",
    "# Essa função retira as stop words de uma lista tokenizada\n",
    "def no_stop_words(token):\n",
    "    clear = []\n",
    "    for element in token:\n",
    "        if element not in prep:\n",
    "            clear.append(element)\n",
    "    return clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 5\n",
    "# Essa função aplica o stemming, pegando a raiz das palavras\n",
    "def to_stemmer(aux):\n",
    "    aux_2 = ''\n",
    "    lista_das_palavras = aux.split()\n",
    "    for palavra in lista_das_palavras:\n",
    "        nova_palavra = stemmer.stem(palavra)\n",
    "        aux_2 += nova_palavra + ' '\n",
    "    aux = aux_2.rstrip()\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar para transformar de lista para string\n",
    "def list_to_string(lista):\n",
    "    return ' '.join(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função final que limpa todo tweet e devolve em formato de string\n",
    "def limpa_tweet(tweet):\n",
    "    return list_to_string(no_stop_words(tokenize(limpa_frase(tweet))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera uma pd.Series do set_frases\n",
    "def frases_to_series(set_frases):\n",
    "    set_frases += ' '\n",
    "    return pd.Series(tokenize(set_frases.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando palavras em variáveis categóricas\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando funções de limpeza e certificação no dataframe de treinamento da base de dados\n",
    "train['Clean'] = train['Treinamento'].apply(limpa_tweet)\n",
    "test['Clean'] = test['Teste'].apply(limpa_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os tweets relevantes dos irrelevantes\n",
    "train_rel = train[train['Relevancia'] == 1]\n",
    "train_irrel= train[train['Relevancia'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera uma pd.Series das palavras relevantes e irrelevantes do training set\n",
    "palavras_rel = frases_to_series(train_rel['Clean'])\n",
    "palavras_irrel = frases_to_series(train_irrel['Clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera duas listas com as palavras relevantes e irrelevantes e gera uma lista total\n",
    "lista_palavras_rel = list(palavras_rel)\n",
    "lista_palavras_irrel = list(palavras_irrel)\n",
    "lista_palavras = lista_palavras_rel + lista_palavras_irrel\n",
    "lista_palavras_sem_repeticao = list(set(lista_palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera um pd.Series da lista com todas as palavras\n",
    "palavras = pd.Series(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lok                     319\n",
      "nao                      69\n",
      "seri                     50\n",
      "rostochorandoaosberr     37\n",
      "assist                   35\n",
      "                       ... \n",
      "pacienc                   1\n",
      "casual                    1\n",
      "exempl                    1\n",
      "pagin                     1\n",
      "pfvr                      1\n",
      "Length: 1121, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Frequencias relativas\n",
    "freq_palavras_relevantes = palavras_rel.value_counts(True)\n",
    "freq_palavras_irrelevantes = palavras_irrel.value_counts(True)\n",
    "freq_palavras_total = palavras.value_counts(True)\n",
    "\n",
    "# Frequencias absolutas\n",
    "freq_palavras_relevantes_abs = palavras_rel.value_counts()\n",
    "freq_palavras_irrelevantes_abs = palavras_irrel.value_counts()\n",
    "freq_palavras_total_abs = palavras.value_counts()\n",
    "\n",
    "print(freq_palavras_relevantes_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(freq_palavras_relevantes.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades \n",
    "\n",
    "Aqui abordaremos os valores das probabilidades que serão imprescindíveis para a construção do modelo. Em primeiro lugar, note que as probabilidade de serem relevantes ou serem irrelevantes podem ser expressas da seguinte forma:\n",
    " \n",
    " * $P(R) \\rightarrow $  Probabilidade de ser relevante\n",
    " * $P(I)=P(R^c) \\rightarrow $  Probabilidade de ser irrelevante\n",
    " \n",
    "Além disso, por serem complementares, temos que: $P(R) + P(I) = P(R) + P(R^c) = 1$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando a razão entre a quantidade de palavras da lista de relevantes pelo número total, temos P_R\n",
    "P_R = len(lista_palavras_rel) / len(lista_palavras)\n",
    "\n",
    "# Por complementar, temos P_Rc\n",
    "P_Rc = 1 - P_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades Condicionais e o Teorema de Bayes\n",
    "Temos que, para o cálculo de probabilidades condicionais, fazemos uso da seguinte relação:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "Onde, \n",
    "* $P(A|B) \\rightarrow $ Probabilidade de A ocorrer, dado que B ocorreu  \n",
    "* $P(A \\cap B) \\rightarrow $ Probabilidade de A ocorrer e B ocorrer\n",
    "* $P(B) \\rightarrow $ Probabilidade de B ocorrer\n",
    "\n",
    "Analogamente, temos que:\n",
    "$$P(B|A) = \\frac{P(B \\cap A)}{P(A)}$$\n",
    "\n",
    "Onde, \n",
    "* $P(B|A) \\rightarrow $ Probabilidade de A ocorrer, dado que B ocorreu  \n",
    "* $P(B \\cap A) \\rightarrow $ Probabilidade de B ocorrer e A ocorrer\n",
    "* $P(A) \\rightarrow $ Probabilidade de B ocorrer\n",
    "\n",
    "Note que as probabilidades da interseção podem comutar os eventos A e B, portanto: $P(B \\cap A) = P(A \\cap B)$\n",
    "\n",
    "Dessa forma, podemos extrair o conhecido Teorema de Bayes:\n",
    "\n",
    "$$P(A|B) = P(B|A).\\frac{P(A)}{P(B)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Classificador de Naive Bayes\n",
    "\n",
    "O Classificador de Naive Bayes se baseia na construção de um modelo bag-of-word. Na análise de sentimento, queremos responder a seguinte pergunta: \"Qual a probabilidade dessa frase ser relevante, dado esse conjunto de palavras?\". Nesse sentido, é necessário computar esse cálculo utilizando probabilidades condicionais e o resultado do teorema de Bayes encontrado na sessão anterior:\n",
    "\n",
    "$$P(R|frase) = \\frac{P(frase|R).P(R)}{P(frase)}$$\n",
    "\n",
    "Dessa forma, nós vamos usar essa relação para encontrar $P(R|frase)$, ou seja, a probabilidade de uma frase ser relevante, dado o conjunto de palavras. Para tanto, tome como exemplo a frase: \"meu avô ama isso\", em termos de notação, queremos encontrar:\n",
    "\n",
    "$$P(R|frase) = \\frac{P(frase|R).P(R)}{P(frase)}$$\n",
    "\n",
    "Para prosseguir, utilizaremos um processo de \"Tokenização\", que consiste em dividir a frase em pedaços menores (as palavras) e assumir que uma palavra não influencia na colocação da outra. Sabemos que isso não é verdade, mas utilizaremos por questões de simplificação (essa é a ingenuidade do classificador de Naive Bayes). Portanto, nosso cálculo ficara da seguinte forma:\n",
    "\n",
    "$$P(frase|R) = P(\"meu\"|R).P(\"avô\"|R).P(\"ama\"|R).P(\"isso\"|R)$$\n",
    "\n",
    "Logo, nossa expressão final será:\n",
    "\n",
    "$$P(R|frase) = \\frac{P(\"meu\"|R).P(\"avô\"|R).P(\"ama\"|R).P(\"isso\"|R).P(R)}{P(frase)}$$\n",
    "\n",
    "Analogamente, para encontrarmos a probabilidade dele ser irrelevante, podemos fazer o mesmo cálculo:\n",
    "\n",
    "$$P(I|frase) = \\frac{P(\"meu\"|I).P(\"avô\"|I).P(\"ama\"|I).P(\"isso\"|I).P(I)}{P(frase)}$$\n",
    "\n",
    "Agora, basta compararmos os valores das probabilidades:\n",
    "\n",
    "Se, $P(R|frase) > P(I|frase)$, então, é mais provável que a frase seja $relevante$\n",
    "\n",
    "\n",
    "Caso contrário, $P(R|frase) < P(I|frase)$, então, é mais provável que a frase seja $irrelevante$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suavização de Laplace\n",
    "\n",
    "É importante ressaltar que para o caso de uma determina palavra em uma frase não pertencer ao nosso conjunto universo, a probabilidade atribuida a essa palavra será zero. Porém, não podemos utilizar a probabilidade de 0 por razões algébricas, portanto, utilizaremos a <b><em>Suavização de Laplace</em></b>. Basicamente essa ferramenta irá nos ajudar a inserir a palavra \"estranha\" no quesito probabilístico das categorias discutidas.\n",
    "\n",
    "$$P(palavra|W) = \\frac{F_{AW}+1}{P_{W}+P_{P}}$$\n",
    "\n",
    "Onde: \n",
    "\n",
    "$ F_{AW} \\rightarrow$ Frequência absoluta da palavra na categoria W\n",
    "    \n",
    "$P_{W} \\rightarrow$ Todas as palavras pertencentes às frases rotuladas como da categoria W\n",
    "    \n",
    "$P_{P} \\rightarrow$ Todas as palavras possíveis sem repetição\n",
    "\n",
    "Nesse sentido, tome $W$ como sendo o evento $R$ e $W^c$ como sendo o evento $I$ ou $R^C$. Dessa forma, a soma do valor 1 faz com que o nosso resultado de $P(R|frase)$ ou $P(I|frase)$ nunca se torne zero, mesmo que a frequência absoluta da palavra seja zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A suavização de Laplace será utilizada para os casos em que uma determinada palavra da frase não se encontra \n",
    "no conjunto universo.\n",
    "'''\n",
    "def smoothing(palavra, relevancia, freq_palavras_abs, alfa=1):\n",
    "    '''\n",
    "    alfa -> Parâmetro de suavização\n",
    "    alfa = 1 (Suavização de Laplace)\n",
    "    alfa < 1 (Suavização de Lidstone)\n",
    "    '''\n",
    "    try:\n",
    "        FAW = freq_palavras_abs[palavra]\n",
    "    except:\n",
    "        FAW = 0\n",
    "    if relevancia == 'R':\n",
    "        return (FAW + alfa) / (len(lista_palavras_rel) + alfa * len(lista_palavras_sem_repeticao))\n",
    "    return (FAW + alfa) / (len(lista_palavras_irrel) + alfa * len(lista_palavras_sem_repeticao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula a probabilidade que queremos para fazer a desigualdade e decidir a categoria mais provável\n",
    "def P(relevancia, frase):\n",
    "    if type(frase) != list:\n",
    "        frase = tokenize(frase)\n",
    "    if relevancia == 'R':\n",
    "        P_F_dado_R = 1\n",
    "        for palavra in frase:\n",
    "            P_F_dado_R *= smoothing(palavra, relevancia, freq_palavras_relevantes_abs)\n",
    "        P_R_dado_F = P_F_dado_R * P_R\n",
    "        return P_R_dado_F\n",
    "            \n",
    "    elif relevancia == 'I' or relevancia == 'Rc':\n",
    "        P_F_dado_Rc = 1\n",
    "        for palavra in frase:\n",
    "            P_F_dado_Rc *= smoothing(palavra, relevancia, freq_palavras_irrelevantes_abs)\n",
    "        P_Rc_dado_F = P_F_dado_Rc * P_Rc\n",
    "        return P_Rc_dado_F\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função final que recorre ao modelo de Naive Bayes\n",
    "def NaiveBayesModel(frase):\n",
    "    if P('R', frase) > P('I', frase):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função final que recorre ao modelo de Naive Bayes\n",
    "def NaiveBayesModel_MonteCarlo(frase):\n",
    "    p1 = P('R', frase)\n",
    "    p2 = P('I', frase)\n",
    "    if p1 > 0.6 or p2 > 0.6:\n",
    "        if p1 > p2:\n",
    "            return 1\n",
    "        return 0\n",
    "    else:\n",
    "        p1_plus_p2 = p1 + p2\n",
    "        lambda_1 = p1 / p1_plus_p2\n",
    "        lambda_2 = p2 / p1_plus_p2\n",
    "        z = random.random()\n",
    "        if z < lambda_1:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise do classificador utilizando a própria base de dados\n",
    "\n",
    "Aqui utilizaremos o classificador para ver sua performance com sua própria base de dados. O intuito é checar a possibilidade de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_train = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@agtha_harkness @mobiusdaavt @pooldeangostoso ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ajud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@chiidenoir amg esquece\\nela shippa thor e loki</td>\n",
       "      <td>1.0</td>\n",
       "      <td>amg esquec shipp thor lok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a menina falando mal de loki puta que pariu se...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>menin fal mal lok put par mat put bom gost</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@octavio_guedes a técnica para dar volume: ao ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tecnic par dar volum inves convoc manifestaco ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@loki__mugo fuliza inanidai ata</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fuliz inanida ata</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>@clintarqueiro @bracinhodeferro @meupai_eadory...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>amor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>eu fico toda coisada pelo loki</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fic tod cois pel lok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>@sylvielaufeydit @bracinhodeferro @meupai_eado...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sei ate oq vai fal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>@kookvlong pode</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pod</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>amo a epifania q estou tendo com loki pq acho ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>amo epifan tend lok acho sent tud sent vend ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia  \\\n",
       "0    @agtha_harkness @mobiusdaavt @pooldeangostoso ...         0.0   \n",
       "1      @chiidenoir amg esquece\\nela shippa thor e loki         1.0   \n",
       "2    a menina falando mal de loki puta que pariu se...         1.0   \n",
       "3    @octavio_guedes a técnica para dar volume: ao ...         0.0   \n",
       "4                      @loki__mugo fuliza inanidai ata         0.0   \n",
       "..                                                 ...         ...   \n",
       "793  @clintarqueiro @bracinhodeferro @meupai_eadory...         0.0   \n",
       "794                     eu fico toda coisada pelo loki         1.0   \n",
       "795  @sylvielaufeydit @bracinhodeferro @meupai_eado...         0.0   \n",
       "796                                    @kookvlong pode         0.0   \n",
       "797  amo a epifania q estou tendo com loki pq acho ...         1.0   \n",
       "\n",
       "                                                 Clean  Modelo  \n",
       "0                                                 ajud       0  \n",
       "1                            amg esquec shipp thor lok       1  \n",
       "2           menin fal mal lok put par mat put bom gost       1  \n",
       "3    tecnic par dar volum inves convoc manifestaco ...       0  \n",
       "4                                    fuliz inanida ata       0  \n",
       "..                                                 ...     ...  \n",
       "793                                               amor       0  \n",
       "794                               fic tod cois pel lok       1  \n",
       "795                                 sei ate oq vai fal       0  \n",
       "796                                                pod       0  \n",
       "797  amo epifan tend lok acho sent tud sent vend ab...       1  \n",
       "\n",
       "[798 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_train['Modelo'] = tabela_train['Clean'].apply(NaiveBayesModel)\n",
    "tabela_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O percentual de verdadeiros positivos foi de: 34.96%\n",
      "O percentual de falsos positivos foi de: 6.27%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivos = tabela_train.loc[(tabela_train['Modelo'] == 1) & (tabela_train['Relevancia'] == 1),:].shape[0]\n",
    "falsos_positivos = tabela_train.loc[(tabela_train['Modelo'] == 1) & (tabela_train['Relevancia'] == 0),:].shape[0]\n",
    "print(f'O percentual de verdadeiros positivos foi de: {100*(verdadeiros_positivos)/tabela_train.shape[0]:.2f}%')\n",
    "print(f'O percentual de falsos positivos foi de: {100*(falsos_positivos)/tabela_train.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O percentual de verdadeiros negativo foi de: 57.14%\n",
      "O percentual de falsos negativo foi de: 1.50%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos = tabela_train.loc[(tabela_train['Modelo'] == 0) & (tabela_train['Relevancia'] == 0),:].shape[0]\n",
    "falsos_negativos = tabela_train.loc[(tabela_train['Modelo'] == 0) & (tabela_train['Relevancia'] == 1),:].shape[0]\n",
    "print(f'O percentual de verdadeiros negativo foi de: {100*(verdadeiros_negativos)/tabela_train.shape[0]:.2f}%')\n",
    "print(f'O percentual de falsos negativo foi de: {100*(falsos_negativos)/tabela_train.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo foi de: 92.11%\n"
     ]
    }
   ],
   "source": [
    "print(f'A acurácia do modelo foi de: {100*(verdadeiros_negativos+verdadeiros_positivos)/tabela_train.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Modelo'] = test['Clean'].apply(NaiveBayesModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O percentual de verdadeiros positivos foi de: 27.36%\n",
      "O percentual de falsos positivos foi de: 27.36%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivos = test.loc[(test['Modelo'] == 1) & (test['Relevancia'] == 1),:].shape[0]\n",
    "falsos_positivos = test.loc[(test['Modelo'] == 1) & (test['Relevancia'] == 0),:].shape[0]\n",
    "print(f'O percentual de verdadeiros positivos foi de: {100*(verdadeiros_positivos)/test.shape[0]:.2f}%')\n",
    "print(f'O percentual de falsos positivos foi de: {100*(falsos_positivos)/test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O percentual de verdadeiros negativo foi de: 38.81%\n",
      "O percentual de falsos negativo foi de: 6.47%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos = test.loc[(test['Modelo'] == 0) & (test['Relevancia'] == 0),:].shape[0]\n",
    "falsos_negativos = test.loc[(test['Modelo'] == 0) & (test['Relevancia'] == 1),:].shape[0]\n",
    "print(f'O percentual de verdadeiros negativo foi de: {100*(verdadeiros_negativos)/test.shape[0]:.2f}%')\n",
    "print(f'O percentual de falsos negativo foi de: {100*(falsos_negativos)/test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo foi de: 66.17%\n"
     ]
    }
   ],
   "source": [
    "print(f'A acurácia do modelo foi de: {100*(verdadeiros_negativos+verdadeiros_positivos)/test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função importante para o último item desse projeto\n",
    "def calcula_metricas(testing):\n",
    "    verdadeiros_positivos = testing.loc[(testing['Modelo'] == 1) & (testing['Relevancia'] == 1),:].shape[0]\n",
    "    falsos_positivos = testing.loc[(testing['Modelo'] == 1) & (testing['Relevancia'] == 0),:].shape[0]\n",
    "    verdadeiros_negativos = testing.loc[(testing['Modelo'] == 0) & (testing['Relevancia'] == 0),:].shape[0]\n",
    "    falsos_negativos = testing.loc[(testing['Modelo'] == 0) & (testing['Relevancia'] == 1),:].shape[0]\n",
    "    acuracia = (verdadeiros_negativos+verdadeiros_positivos)\n",
    "    return (verdadeiros_positivos * 100)/test.shape[0], (falsos_positivos * 100)/test.shape[0], (verdadeiros_negativos * 100)/test.shape[0], (falsos_negativos * 100)/test.shape[0], (acuracia * 100)/test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapa de Calor\n",
    "Para visualizar melhor os percentuais, vamos utilizar a biblioteca Seaborn para plotar um mapa de calor, a partir de uma tabela cruzada que será criada na célula seguinte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabela_cruzada = pd.crosstab(test.Relevancia, test.Modelo, normalize=True)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.title('Mapa de calor')\n",
    "sn.heatmap(tabela_cruzada, annot=True, annot_kws={\"size\": 30}, fmt='.1%', cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   No classificador automático criado, que tem por objetivo adotar critérios acerca dos sentimentos sobre a série, como visto  no mapa de calor e seus dados de precisão, há uma acurácia de 53.50%, com um percentual de verdadeiros negativo de 37.50% e um percentual de falsos negativo de 18.00%.\n",
    "   \n",
    "   Dentro deste universo, é essencial acrescentar que os grandes responsáveis por esses erros são os falsos positivos, já que trazem uma caracterização errônea ao classificador em questão. Desta forma, também é importante destacar que ao promover o uso de um data base pequeno, o algorítmo criado apresenta uma classificação mais arbritrária, enquanto que se a mesma for feita por mais informações e informações mais abrangentes, apresentará resultados mais satisfatórios e precisos, dentro de uma 'subjetividade' criada por probabilidades e espaços amostrais que envolvem os dados em questão. Com isso, sendo possível receber um output biinário resposável por definir os mesmos em relevantes, ou ainda, irrelevantes. Ou seja, classificar automaticamente os dados em questão.\n",
    "  \n",
    "   Contudo, pode-se definir, por fim, um funcionamento adequado ao próprio classificador, mas não ideal, sendo que uma vez que \"naive\" (ou seja, ingênuo) desconsidera a relação entre as palavras, abrindo brechas para classificações incorretas acerca dos procedimentos de sarcasmo, dupla negação, ironia, ambiguidade e figuras de linguagem - sendo sarcasmo e dupla negação discutidos abaixo. Fato que mesmo o aumento dos dados coletados por ele podem não sanar, tendo em mente apenas a eficácia da análise matemática e não de granática, sentido ou sintaxe aplicadas aos tweets.\n",
    "   \n",
    "   Através disso, tendo em vista o funcionamento adequado do produto em questão (dentro de aspectos matemáticos), essa funcionalidade poderia de fato ser expandida para outros universos, como a comparação de avaliações positivas e negativas acerca de um determinado produto, ou ainda, coletando a relevância de feedbacks apresentados pelos usuários de determidao produto-serviço, a fim de potencializar a sua eficácia e produtividade. Deste modo, sendo intrínseco ao projeto a necessidade contínua de alimentação financeira, para que o classificador criado possa continuar em andamento, se desenvolvendo e abrangindo maiores ramos no mundo de coleta e classificação de dados, tanto para pesquisa de satisfação quanto para melhoria dos ideias de certa empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por que a acurácia do classificador é maior quando se utiliza a própria base de treinamento e menor quando se utiliza a base de teste?\n",
    "\n",
    "Sobretudo, num contexto de um pequeno data set, ocorrerá um efeito chamado <b>Overfitting</b>, que ocorre devido ao fato de o conjunto de treinamento não ser suficientemente grande para gerar classificações mais acertivas quando o sistema recebe novas instâncias (novos tweets). Em outras palavras, o classificador se ajusta muito bem ao conjunto de treinamento, porém não possui uma generalização significativa na classificação do conjunto de teste.\n",
    "\n",
    "Esse efeito pode ser simbolizado pelo gráfico a seguir:\n",
    "\n",
    "<img src=\"assets/overfitting_2.png\" width=400 >\n",
    "<center><b>Figura 1 - Visualização do overfitting para data sets pequenos</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador?\n",
    "\n",
    "Como vimos anteriormente, existe uma simplificação que fizemos na implementação do modelo que pode prejudicar o julgamento do algoritmo ao receber uma nova instância (novo tweet). Em tópicos anteriores vimos que as considerações foram estritamente algébricas, não levando em conta o valor semântico, gramático e a influência de uma palavra às demais da frase.\n",
    "\n",
    "Nesse sentido, ao utilizarmos o próprio classificador para alimentar a base de treinamento, estaríamos propagando um viés cada vez maior, prejudicando o treinamento do nosso modelo. Dessa forma, é preciso que os tweets sejam rotulados manualmente e com um critério estático, mesmo que isso apresente um certo grau de subjetividade. É importante mencionar que esse tipo de sistema de aprendizado é Supervisionado, portanto, é necessário que nosso conjunto de treinamento esteja rotulado de forma adequada para que obtenhamos o máximo de êxito ao classificar uma nova instância.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sarcasmo e dupla negação\n",
    "\n",
    "<b>1) Sarcasmo</b>\n",
    "\n",
    "Este tópico é pautado em uma consideração que fizemos para a construção do modelo. Como vimos, por questões de simplificação, o classificador de Naive Bayes considera a independência entre as palavras (<b>a ingenuidade de Naive Bayes</b>). Apesar de ser uma consideração razoável, é possível prever que o classificador não funciona muito bem diante de um tweet sarcástico, por exemplo. \n",
    "\n",
    "Diante disso, acompanhe um caso que pode ser um bom exemplo disso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase 1 é RELEVANTE\n"
     ]
    }
   ],
   "source": [
    "frase_1 = 'eu amo loki tanto quanto tomar uma paulada'\n",
    "if NaiveBayesModel(frase_1) == 1:\n",
    "    print('A frase 1 é RELEVANTE')\n",
    "else:\n",
    "    print('A frase 1 é IRRELEVANTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2) Dupla Negação</b>\n",
    "\n",
    "Analogamente ao caso anterior, é possível estender essa análise para frases com dupla negação. \n",
    "\n",
    "Diante disso, acompanhe um caso que pode ser um bom exemplo disso:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase 2 é RELEVANTE\n"
     ]
    }
   ],
   "source": [
    "frase_2 = 'loki não é nada agradável'\n",
    "if NaiveBayesModel(frase_2) == 1:\n",
    "    print('A frase 2 é RELEVANTE')\n",
    "else:\n",
    "    print('A frase 2 é IRRELEVANTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os exemplos acima é possível inferir, portanto, que tweets de caráter sarcástico ou com dupla negação muito provavelmente serão classificados de maneira errônea. Isso se deve, sobretudo, à <b>ingenuidade do classificador de Naive Bayes</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novos cenários para o classificador de Naive Bayes\n",
    "\n",
    "<b>1)</b> A aplicação do modelo ingênuo de Bayes para prever a doença de Alzheimer a partir de dados de todo o genoma (Wei Wei, et al. 2011)\n",
    "\n",
    "Nesse artigo, é utilizado o modelo de Naive Bayes para identificar e prever a doença de Alzheimer. O ponto princípio da implementação se encontro no tópico \"<b>The naive Bayes model</b>\", onde ele mostra a consideração que aqui discutimos:\n",
    "\n",
    "<img src=\"assets/ox_article.png\" width=400 >\n",
    "<center><b>Figura 1 - Consideração da Ingenuidade do modelo</b></center>\n",
    "\n",
    "Nesse caso, as features são os componentes pertencentes ao genoma (fazendo o paralelo, seriam a substituição das palavras dos nossos tweets). Dessa forma, é possível ver uma primeira grande aplicação para o modelo de Naive Bayes, que ainda não havia sido discutida.\n",
    "\n",
    "* Fonte: https://academic.oup.com/jamia/article/18/4/370/732731?login=true\n",
    "\n",
    "<b>2)</b> Uma nova aplicação do classificador Naive Bayes na previsão de energia fotovoltaica (Ramazan Bayindir, et al. 2017)\n",
    "\n",
    "Nesse artigo, é utilizado o modelo de Naive Bayes para identificar e prever a quantidade de energia gerada por paineis fotovoltaicos. Os pesquisadores utilizaram um conjunto de dados coletados por 1 ano, que registram valores de varias features como temperatura e duração total do sol. \n",
    "\n",
    "As aplicações do modelo de Naive Bayes nesse artigo podem ser de fundamental importância no mundo contemporânea, haja vista a necessidade de cada vez mais aplicações de energias limpas (como a energia solar) e para tanto, é necessário um aparato tecnológico consistente para tal atividade.\n",
    "\n",
    "* Fonte: https://ieeexplore.ieee.org/abstract/document/8260684\n",
    "\n",
    "<b>3)</b> Filtro de spam utilizando o modelo de Naive Bayes (DILIP KUMAR, et al. 2018)\n",
    "\n",
    "Nesse artigo do famoso site Kaggle, é possível ver uma aplicação muito interessante (e presente no nosso cotidiano) de um filtro de Spam utilizando o modelo de Naive Bayes. Com um grande número de e-mails já rotulados, será possível criar o modelo exatamente como fizemos nesta aplicação. Portanto, temos uma mudança significativa de ambiente, porém utilizaremos o mesmo sistema de aprendizado para tal.\n",
    "\n",
    "\n",
    "* Fonte: https://www.kaggle.com/dilip990/spam-ham-detection-using-naive-bayes-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sugestões de melhorias para o Classificador\n",
    "\n",
    "##### 1) Stemming and Lemmatization\n",
    "\n",
    "   O stemming de palavras pode ser um caminho muito pertinente para a melhoria da acurácia (Utilizado nesse projeto). A técnica consiste em transformar as palavras da frase em sua raiz (que pode acabar resultando em palavras que não existe). Em contrapartida, o Lemmatization obtém sua forma canonica e gramaticalmente correta. Ambas as técnicas despendem um grande custo computacional e impactam a performance da classificação, porém podem ser uma solução para elevar o percentual de acurácia.\n",
    "   \n",
    "   Nesse sentido, é possível utilizar a biblioteca de linguagem natural <b>(nltk - Natural Language Toolkit)</b>, caso você não tenha essa biblioteca instalada utilize o comando:\n",
    "\n",
    ">**!pip install nltk**\n",
    "\n",
    "   * Para mais informações, acesse o site oficial: https://www.nltk.org/\n",
    "   \n",
    "   * Outro link que pode ajudar: [Artigo Datacamp tutorial](https://www.datacamp.com/community/tutorials/stemming-lemmatization-python?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=&utm_network=g&utm_adpostion=&utm_creative=278443377095&utm_targetid=aud-392016246653:dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=1001773&gclid=Cj0KCQjwv5uKBhD6ARIsAGv9a-xGXnN7nhmmTGQ-Fdgb38Qz92hH3S3LnFQOyoOz1Mta4OCa4enwGg8aAseSEALw_wcB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Formação de N-gramas de palavras\n",
    "\n",
    "   A formação de N-gramas pode contrabalancear o problema da Ingenuidade do modelo. A consideração de que as palavras são independentes umas das outras, apesar de funcionar, prejudica o julgamento do sistema de aprendizado para novas instâncias. Logo, uma maneira de deixar o modelo mais sólido é construir N-gramas na formação das palavras.\n",
    "   Segundo estudos (Vlado Keˇselj, et al 2003), é possível melhorar significativamente a acurácia de textos em inglês utilizando N-gramas com N entre 4 e 8. Portanto, um tópico que poderia ser abordado é a formação de N-gramas.\n",
    "   \n",
    "   Nesse sentido, é possível utilizar a biblioteca de linguagem natural <b>(nltk - Natural Language Toolkit)</b>, caso você não tenha essa biblioteca instalada utilize o comando:\n",
    "\n",
    ">**!pip install nltk**\n",
    "\n",
    "   Com a biblioteca instalada, utilize os comandos a seguir para gerar seus N-gramas (lembre-se da tokenização):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Estou', 'interessado')\n",
      "('interessado', 'em')\n",
      "('em', 'aprender')\n",
      "('aprender', 'Machine')\n",
      "('Machine', 'Learning')\n",
      "('Estou', 'interessado', 'em')\n",
      "('interessado', 'em', 'aprender')\n",
      "('em', 'aprender', 'Machine')\n",
      "('aprender', 'Machine', 'Learning')\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "my_text = 'Estou interessado em aprender Machine Learning'\n",
    "words = tokenize(my_text)\n",
    "my_bigrams = nltk.bigrams(words)\n",
    "my_trigrams = nltk.trigrams(words)\n",
    "for word in my_bigrams:\n",
    "    print(word)\n",
    "for word in my_trigrams:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para mais informações, acesse o site oficial: https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Aumentar o tamanho da base de dados de treinamento\n",
    "\n",
    "   Das várias propostas possíveis, essa é uma das mais intuitivas. Em tópicos anteriores, falamos a respeito dos efeitos negativos de se utilizar uma base de dados pequena, ao aumentarmos o nosso conjunto de amostras (lembre-se do bag of word model) daremos mais instâncias para o nosso sistema se basear e aprender a classificar instâncias não vistas antes. \n",
    "\n",
    "Dessa forma, uma saída possível é classificarmos cada vez mais tweets para alimentar mais nossa base de treinamente e conferir maior acurácia para nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Utilização do método de Monte Carlo para variáveis aleatórias\n",
    "\n",
    "   Como vimos até aqui, o modelo de Naive Bayes utiliza a comparação de duas probabilidades condicionais através do teorema de Bayes. Para decidir a relevância ou não, só verificamos qual probabilidade é maior e atribuimos a esta a classifição da nova instância. Porém, apesar de ser considerada a mais provável, ainda é possível que a menos provável seja a classificação real. Aqui entra o método de Monte Carlo. É possível gerar números aleatório no intervalo de 0 a 1, caso o número gerado seja menor que a probabilidade de ser relevante dado um tweet, essa instância será classificada como relevante, caso contrário, como irrelevante. Vale ressaltar que esse método provavelmente será mais eficaz quando a base de dados for suficientemente grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@agtha_harkness @mobiusdaavt @pooldeangostoso ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ajud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@chiidenoir amg esquece\\nela shippa thor e loki</td>\n",
       "      <td>1.0</td>\n",
       "      <td>amg esquec shipp thor lok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a menina falando mal de loki puta que pariu se...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>menin fal mal lok put par mat put bom gost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@octavio_guedes a técnica para dar volume: ao ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tecnic par dar volum inves convoc manifestaco ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@loki__mugo fuliza inanidai ata</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fuliz inanida ata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Total  Relevancia  \\\n",
       "0  @agtha_harkness @mobiusdaavt @pooldeangostoso ...         0.0   \n",
       "1    @chiidenoir amg esquece\\nela shippa thor e loki         1.0   \n",
       "2  a menina falando mal de loki puta que pariu se...         1.0   \n",
       "3  @octavio_guedes a técnica para dar volume: ao ...         0.0   \n",
       "4                    @loki__mugo fuliza inanidai ata         0.0   \n",
       "\n",
       "                                               Clean  \n",
       "0                                               ajud  \n",
       "1                          amg esquec shipp thor lok  \n",
       "2         menin fal mal lok put par mat put bom gost  \n",
       "3  tecnic par dar volum inves convoc manifestaco ...  \n",
       "4                                  fuliz inanida ata  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split = pd.read_excel(filename, sheet_name = 'Teste').rename(columns={'Teste':'Total'})\n",
    "\n",
    "train_split = pd.read_excel(filename, sheet_name = 'Treinamento').rename(columns={'Treinamento':'Total'})\n",
    "\n",
    "#Concatenando\n",
    "full_data = pd.concat([train_split,test_split])\n",
    "\n",
    "#Limpando os tweets\n",
    "full_data['Clean']=full_data['Total'].apply(limpa_tweet)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_hist=[]\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    #training_data, testing_data = train_test_split(full_data, test_size=0.2, random_state=random.randint(1,500))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(full_data[['Clean','Relevancia']],full_data.Relevancia,\n",
    "    test_size=0.3)\n",
    "    \n",
    "    train_rel_new = X_train[X_train['Relevancia']==1]\n",
    "    train_irrel_new = X_train[X_train['Relevancia']==0]\n",
    "    \n",
    "    palavras_rel = frases_to_series(train_rel_new['Clean'])\n",
    "    palavras_irrel = frases_to_series(train_irrel_new['Clean'])\n",
    "    \n",
    "    # Gera duas listas com as palavras relevantes e irrelevantes e gera uma lista total\n",
    "    lista_palavras_rel = list(palavras_rel)\n",
    "    lista_palavras_irrel = list(palavras_irrel)\n",
    "    lista_palavras = lista_palavras_rel + lista_palavras_irrel\n",
    "    lista_palavras_sem_repeticao = list(set(lista_palavras))\n",
    "    total = pd.Series(lista_palavras)\n",
    "\n",
    "    # Frequencias absolutas\n",
    "    freq_palavras_relevantes_abs = palavras_rel.value_counts()\n",
    "    freq_palavras_irrelevantes_abs = palavras_irrel.value_counts()\n",
    "    freq_palavras_total_abs = palavras.value_counts()\n",
    "\n",
    "    P_R = len(lista_palavras_rel) / len(total)\n",
    "\n",
    "    # Por complementar, temos P_Rc\n",
    "    P_Rc = len(lista_palavras_irrel) / len(total)\n",
    "    \n",
    "    assert P_R+P_Rc==1\n",
    "\n",
    "    X_test['Modelo'] = X_test['Clean'].apply(NaiveBayesModel)\n",
    "\n",
    "    verdadeiros_positivos = X_test.loc[(X_test['Modelo'] == 1) & (X_test['Relevancia'] == 1),:].shape[0]\n",
    "    verdadeiros_negativos = X_test.loc[(X_test['Modelo'] == 0) & (X_test['Relevancia'] == 0),:].shape[0]\n",
    "    acuracia = (verdadeiros_positivos + verdadeiros_negativos)/X_test.shape[0]\n",
    "    lista_hist.append(acuracia * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "faixa=np.arange(30,99,1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(lista_hist, bins=faixa, edgecolor='black', density=False)\n",
    "plt.title('Frequencia dos scores do modelo')\n",
    "plt.ylabel('Frequência')\n",
    "plt.xlabel('Porcentagem de acerto (%)')\n",
    "plt.xlim(52.5,72.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score máximo:  70.67\n",
      "Score mínimo:  59.33\n",
      "Score médio:  65.22\n"
     ]
    }
   ],
   "source": [
    "print('Score máximo: ', round(max(lista_hist), 2))\n",
    "print('Score mínimo: ', round(min(lista_hist), 2))\n",
    "print('Score médio: ', round(sum(lista_hist)/len(lista_hist), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Como podemos ver, a maneira como dispomos os conjuntos de teste e treino pode influenciar no score que o modelo pode alcançar. Tendo isso me vista, é imprescindível que estudos com diferentes disposições de conjuntos sejam feitas como no item anterior. Analisando o histograma, podemos observar que não seria produtivo utilizar uma única partição de conjunto de treinamento/teste, pelo falo de existir a possibilidade tanto de se obter scores elevados quanto de se obter scores mais baixos. Dessa forma, para a melhor construção do sistema de aprendizado, é imprescindível que se leve em consideração as partições de treinamento/teste que melhor se adequam aos objetivos do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Subclassificações:\n",
    "\n",
    "*Categorias Intermediárias*\n",
    "\n",
    "Criando categorias intermediárias baseadas na probabilidade relativa estipulada pelo modelo\n",
    "\n",
    "Aquém das categorias Relevante e Irrelevante é possível determinar subclassificações como: Muito Irrelevante, Irrelevante, Neutro, Reletante e Muito Relevante.\n",
    "\n",
    "Sendo o tweet X e Y, ambos classificados como relevantes. Na nova classificação considera-se que caso a probabilidade de um X ser relevante seja consideravelmente maior do que a probabilidade de um Y ser relevante, pode-se dividir essa classe em mais duas categorias. Sendo assim, tweet X a pertence a subcategoria mais relevante, enquanto que o tweet Y faz parte da menos relevante, ambos dentro da categoria \"Relevante\" (com graus da mesma distintos). Da mesma forma tweets \"Irrelevantes\" podem ser classificados, já que dentro de suas probabilidades negativas, encontram-se twees mais irrelevantes e menos irrelevantes.\n",
    "\n",
    "Sendo assim, no caso de um tweet w, que por sua vez, possui uma diferença de probabilidade ($P(R|tweetW)-P(I|tweetW)$) próxima de zero, pode-se subclassificá-lo como um tweet neutro (ou seja, nem relevante e nem irrelevante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_absoluta(palavra,f_abs):\n",
    "    \"\"\"\n",
    "    Determina as vezes que a palavra apareceu \n",
    "    na respectiva categoria, sendo ela relevante ou irrelevante\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        return f_abs[palavra]\n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def P_f (Relevancia, tweet):\n",
    "    return P(\"R\", tweet)*P_R/(P(Relevancia, tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_categories(tweet):\n",
    "    \"\"\"\n",
    "    Diferença entre as probabilidades de Relevante\n",
    "    e Irrelevante\n",
    "    \"\"\"\n",
    "    return ((P(\"R\",tweet)*P_R)/P_f('R', tweet)) -((P(\"I\",tweet)*P_Rc)/P_f('I', tweet))\n",
    "\n",
    "# OBS: a função P (Função que calcula a probabilidade que queremos para fazer a desigualdade e decidir a categoria mais \n",
    "# provável) foi reutilizada! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6.215533e-11\n",
       "1     -6.985989e-20\n",
       "2      6.706150e-15\n",
       "3     -1.214690e-23\n",
       "4     -5.390588e-11\n",
       "           ...     \n",
       "196   -2.530708e-27\n",
       "197    1.009385e-27\n",
       "198   -3.316103e-08\n",
       "199   -8.908614e-38\n",
       "200    4.632219e-32\n",
       "Name: Prob, Length: 201, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_degree=test.copy()\n",
    "test_degree['Prob']=test_degree['Clean'].apply(Naive_Bayes_categories)\n",
    "test_degree.Prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Categories(p):\n",
    "    \n",
    "    '''\n",
    "   Rotula em: Muito Irrelevante, Irrelevante, Neutro, Relevante ou Muito Relevante\n",
    "    '''\n",
    "    \n",
    "    #Lista com os valores de probabilidade em ordem.\n",
    "    p_lista = test_degree.Prob.sort_values().tolist()\n",
    "    \n",
    "    #Ponto que divide relevantes e irrelevantes na lista ordenada de probabilidade.\n",
    "    virada = 0\n",
    "    \n",
    "    #Último elemento da lista:\n",
    "    ultimo = len(p_lista)\n",
    "    \n",
    "    for i, value in enumerate(p_lista):\n",
    "            \n",
    "            if(value < 0):           \n",
    "                continue\n",
    "            else:\n",
    "                #Posição em que os valores mudam para positivo\n",
    "                virada = i                 \n",
    "                break\n",
    "    \n",
    "    #Probabilidade neutra para valores próximos de 0\n",
    "    if p in p_lista[virada - 10 : virada + 20]:\n",
    "         return 'Neutro'                       \n",
    "    \n",
    "    \n",
    "    else:    \n",
    "        \n",
    "        # Probabilidade negativa 2 Subclasses\n",
    "        if p < 0:\n",
    "            \n",
    "            # Muito Irrelevantes (muito  negativos)\n",
    "            if p in p_lista[0 : math.ceil((virada - 10) / 2)]:\n",
    "                return 'Muito Irrelevante'\n",
    "            \n",
    "            # Irrelevantes (negativos)\n",
    "            return 'Irrelevante'\n",
    "        \n",
    "        # Probabilidade positiva 2 subclasses\n",
    "        else:\n",
    "            \n",
    "            # Relevantes (menos positivos)\n",
    "            if p in p_lista[(virada + 20) : math.ceil((virada + 20) + (ultimo - (virada + 20)) / 2)]:\n",
    "                return 'Relevante'\n",
    "            \n",
    "            # Muito Relevantes (Valores mais positivos)\n",
    "            return 'Muito Relevante'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Grau de Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demorou mas finalmente tô assistindo loki</td>\n",
       "      <td>1</td>\n",
       "      <td>demor final assist lok</td>\n",
       "      <td>1</td>\n",
       "      <td>6.215533e-11</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@benuron_ @beatriz__asf xiu nao quero saber de...</td>\n",
       "      <td>0</td>\n",
       "      <td>xiu nao quer sab voc import lok viv</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.985989e-20</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ᅟᅟ\\n\\neu e a tia sylvie atormentando o tio lok...</td>\n",
       "      <td>1</td>\n",
       "      <td>tia sylvi atorment tio lok</td>\n",
       "      <td>1</td>\n",
       "      <td>6.706150e-15</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vote 24 pra eleger loki como presidente em 202...</td>\n",
       "      <td>1</td>\n",
       "      <td>vot 24 eleg lok president 2022 brilh</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.214690e-23</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indo de descer com o loki e mimir</td>\n",
       "      <td>0</td>\n",
       "      <td>indo desc lok mim</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.390588e-11</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@hiddlesfeyson nao consigo escolher amo todos ...</td>\n",
       "      <td>1</td>\n",
       "      <td>nao consig escolh amo tod vdd amo lok thor 1 d...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.599347e-36</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@fcmurtadha essa é uma teoria interessante e m...</td>\n",
       "      <td>0</td>\n",
       "      <td>teor interess muit possivel acontec mesm nao s...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.712304e-25</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@hiddlesgfs abutre e loki</td>\n",
       "      <td>0</td>\n",
       "      <td>abutr lok</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.504878e-06</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@iaursfly @ianacarioca manda foto do loki</td>\n",
       "      <td>0</td>\n",
       "      <td>mand fot lok</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.581796e-06</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>together. for all time. — sylki au\\n\\ndois lok...</td>\n",
       "      <td>1</td>\n",
       "      <td>togeth all tim sylki au dois lok linh temp pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.655229e-100</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@loki__mugo 100.00 + ode16jdb1p confirmed 🙌</td>\n",
       "      <td>0</td>\n",
       "      <td>100 00 ode16jdb1p confirmed maosparacim</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.077626e-17</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>primeiro que ela é uma otaria sem sorte, segun...</td>\n",
       "      <td>1</td>\n",
       "      <td>primeir otar sort segund tud mund sab melhor s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.858960e-32</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@torystyliinson @loki_l4ufeys0n ele tá fazendo...</td>\n",
       "      <td>0</td>\n",
       "      <td>ta faz almoc depo voc vir my lady</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.869879e-20</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>loki apareceu 😈</td>\n",
       "      <td>1</td>\n",
       "      <td>lok aparec rostosorridentecomchifr</td>\n",
       "      <td>1</td>\n",
       "      <td>6.564786e-09</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@fernando21neto essa série é horrível, perdi m...</td>\n",
       "      <td>1</td>\n",
       "      <td>seri horrivel perd temp kkkk aind nao dei trab...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.136772e-30</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@pedrocertezas síndrome totalmente desvaloriza...</td>\n",
       "      <td>1</td>\n",
       "      <td>sindrom total desvaloriz car lok antagon vila</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.394979e-24</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@adolesposting esse meme tem mais variantes do...</td>\n",
       "      <td>0</td>\n",
       "      <td>mem variant lok</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.406531e-08</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hoje vou começar loki e continuar ratched ✅</td>\n",
       "      <td>1</td>\n",
       "      <td>hoj vou comec lok continu ratched marcadeselec...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.734735e-20</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@mobiusdaavt @loki_l4ufeys0n @torystyliinson l...</td>\n",
       "      <td>0</td>\n",
       "      <td>lind redheart</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.480045e-07</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>loki\\n\\n\"a premissa utilizada ao longo da séri...</td>\n",
       "      <td>0</td>\n",
       "      <td>lok premiss utiliz long seri otim element just...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.420468e-53</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@g1 certamente trata-se de uma variante, loki ...</td>\n",
       "      <td>1</td>\n",
       "      <td>cert trat variant lok tom cont brasil variant ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.983838e-35</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>eu li loki disfarçado de zeca pagodinho https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>li lok disfarc zec pagodinh</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.466209e-15</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meus irmãos discutindo se o loki é “menina” ou...</td>\n",
       "      <td>1</td>\n",
       "      <td>irma discut lok menin menin fez dia kkkkkk</td>\n",
       "      <td>0</td>\n",
       "      <td>3.056563e-23</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loki é mt eu ensinando história pra carmen um ...</td>\n",
       "      <td>1</td>\n",
       "      <td>lok mt ensin histor carmen dia antes prov</td>\n",
       "      <td>1</td>\n",
       "      <td>1.355732e-23</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>o loki não acorda logo to bem mal</td>\n",
       "      <td>0</td>\n",
       "      <td>lok nao acord log bem mal</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.085020e-15</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>segundo meus amigos meu gosto p homem eh mt pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>segund amig gost p hom eh mt previsivel tod sa...</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.364123e-44</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@mobiusdaavt @torystyliinson @loki_l4ufeys0n @...</td>\n",
       "      <td>0</td>\n",
       "      <td>peg dois faz trisal</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.975575e-12</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@mobiusdaavt @loki_l4ufeys0n @pooldeangostoso ...</td>\n",
       "      <td>0</td>\n",
       "      <td>aceit quadrisal rostocomamaosobreaboc rostocom...</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.303479e-13</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>allora o fate incontrare thor e loki o vi denu...</td>\n",
       "      <td>0</td>\n",
       "      <td>allor fat incontrar thor lok vi denunci</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.000875e-21</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>eu: vou pra casa dormir e descansar\\nimpecilho...</td>\n",
       "      <td>0</td>\n",
       "      <td>vou cas dorm descans impecilh lok surt quer brinc</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.520047e-25</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>@romanoffnatash2 cuidado pra não cair 😉</td>\n",
       "      <td>0</td>\n",
       "      <td>cuid nao cair rostocomolhopisc</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.048838e-11</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>o loki vai lutar contra o nikolas tesla *?????...</td>\n",
       "      <td>0</td>\n",
       "      <td>lok vai lut contr nikol tesl</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.519391e-17</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>queria um funko do loki aff</td>\n",
       "      <td>1</td>\n",
       "      <td>quer funk lok aff</td>\n",
       "      <td>1</td>\n",
       "      <td>3.167916e-11</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>@posteitinerante a do loki é perfeita</td>\n",
       "      <td>1</td>\n",
       "      <td>lok perfeit</td>\n",
       "      <td>1</td>\n",
       "      <td>4.811239e-06</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>@bracinhodeferro @loki_l4ufeys0n @meupai_eador...</td>\n",
       "      <td>0</td>\n",
       "      <td>voc entreg</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.095780e-06</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>@rsrssep @lllrieieiei yt deve ta bugado mano ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>yt dev ta bug man seman pass tav muit</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.346048e-23</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>@melhornao777 @loki_trem @bakzinfx7 @loud_thur...</td>\n",
       "      <td>0</td>\n",
       "      <td>nfa tim pipoc sempr cop nobru don org vcs pass...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.010089e-59</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>@mirronme @g1ncanafandom @moonwithpotter @suit...</td>\n",
       "      <td>0</td>\n",
       "      <td>eit lok vai ta mesm tim gent vou pod continu d...</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.352945e-34</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>@wizwarsd fodase o loki</td>\n",
       "      <td>1</td>\n",
       "      <td>fodas lok</td>\n",
       "      <td>1</td>\n",
       "      <td>6.273745e-06</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mentira porque em 2018 o loki disse que a porc...</td>\n",
       "      <td>1</td>\n",
       "      <td>ment porqu 2018 lok diss porc sol ia brilh por...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.959366e-90</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>o loki morreu ????737383$;@9¥&amp;amp;@(849($4@;89...</td>\n",
       "      <td>1</td>\n",
       "      <td>lok morr 737383 amp 849 4 894 amp</td>\n",
       "      <td>1</td>\n",
       "      <td>2.689205e-24</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>*sylvie e loki sentados em um banco*\\n\\nravonn...</td>\n",
       "      <td>0</td>\n",
       "      <td>sylvi lok sent banc ravonn ue vcs parec tao tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.377022e-67</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>@anderson839517 @nacaomarvei como assim?? \\nel...</td>\n",
       "      <td>0</td>\n",
       "      <td>assim so surg depo vingador tinh derrot lok ul...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.272071e-66</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>a serie do loki e muito boa</td>\n",
       "      <td>1</td>\n",
       "      <td>seri lok muit boa</td>\n",
       "      <td>1</td>\n",
       "      <td>5.966817e-10</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>@mobiusdaavt @torystyliinson @loki_l4ufeys0n é...</td>\n",
       "      <td>0</td>\n",
       "      <td>clar amorzinh</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.253011e-06</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>que vergonha dizer isto agora, porque já devia...</td>\n",
       "      <td>0</td>\n",
       "      <td>vergonh diz agor porqu dev ter vist ha bue fin...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.233481e-44</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>gente, a sylvie e o loki não são a mesma pesso...</td>\n",
       "      <td>0</td>\n",
       "      <td>gent sylvi lok nao sao mesm pesso imagin vcs e...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.500161e-93</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>obra de @moopzies \\n\\n#marvel #loki https://t....</td>\n",
       "      <td>0</td>\n",
       "      <td>obra</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.609808e-04</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>@cnn, aqui, até loki seleciona mídia de qualid...</td>\n",
       "      <td>0</td>\n",
       "      <td>aqu ate lok selecion mid qualidad par acompanh...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.392892e-35</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>eu na minha analise do loki https://t.co/lcglw...</td>\n",
       "      <td>1</td>\n",
       "      <td>minh analis lok</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.423858e-08</td>\n",
       "      <td>Muito Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  Relevancia  \\\n",
       "0           demorou mas finalmente tô assistindo loki           1   \n",
       "1   @benuron_ @beatriz__asf xiu nao quero saber de...           0   \n",
       "2   ᅟᅟ\\n\\neu e a tia sylvie atormentando o tio lok...           1   \n",
       "3   vote 24 pra eleger loki como presidente em 202...           1   \n",
       "4                   indo de descer com o loki e mimir           0   \n",
       "5   @hiddlesfeyson nao consigo escolher amo todos ...           1   \n",
       "6   @fcmurtadha essa é uma teoria interessante e m...           0   \n",
       "7                           @hiddlesgfs abutre e loki           0   \n",
       "8           @iaursfly @ianacarioca manda foto do loki           0   \n",
       "9   together. for all time. — sylki au\\n\\ndois lok...           1   \n",
       "10        @loki__mugo 100.00 + ode16jdb1p confirmed 🙌           0   \n",
       "11  primeiro que ela é uma otaria sem sorte, segun...           1   \n",
       "12  @torystyliinson @loki_l4ufeys0n ele tá fazendo...           0   \n",
       "13                                    loki apareceu 😈           1   \n",
       "14  @fernando21neto essa série é horrível, perdi m...           1   \n",
       "15  @pedrocertezas síndrome totalmente desvaloriza...           1   \n",
       "16  @adolesposting esse meme tem mais variantes do...           0   \n",
       "17        hoje vou começar loki e continuar ratched ✅           1   \n",
       "18  @mobiusdaavt @loki_l4ufeys0n @torystyliinson l...           0   \n",
       "19  loki\\n\\n\"a premissa utilizada ao longo da séri...           0   \n",
       "20  @g1 certamente trata-se de uma variante, loki ...           1   \n",
       "21  eu li loki disfarçado de zeca pagodinho https:...           0   \n",
       "22  meus irmãos discutindo se o loki é “menina” ou...           1   \n",
       "23  loki é mt eu ensinando história pra carmen um ...           1   \n",
       "24                  o loki não acorda logo to bem mal           0   \n",
       "25  segundo meus amigos meu gosto p homem eh mt pr...           0   \n",
       "26  @mobiusdaavt @torystyliinson @loki_l4ufeys0n @...           0   \n",
       "27  @mobiusdaavt @loki_l4ufeys0n @pooldeangostoso ...           0   \n",
       "28  allora o fate incontrare thor e loki o vi denu...           0   \n",
       "29  eu: vou pra casa dormir e descansar\\nimpecilho...           0   \n",
       "30            @romanoffnatash2 cuidado pra não cair 😉           0   \n",
       "31  o loki vai lutar contra o nikolas tesla *?????...           0   \n",
       "32                        queria um funko do loki aff           1   \n",
       "33              @posteitinerante a do loki é perfeita           1   \n",
       "34  @bracinhodeferro @loki_l4ufeys0n @meupai_eador...           0   \n",
       "35  @rsrssep @lllrieieiei yt deve ta bugado mano ,...           0   \n",
       "36  @melhornao777 @loki_trem @bakzinfx7 @loud_thur...           0   \n",
       "37  @mirronme @g1ncanafandom @moonwithpotter @suit...           0   \n",
       "38                            @wizwarsd fodase o loki           1   \n",
       "39  mentira porque em 2018 o loki disse que a porc...           1   \n",
       "40  o loki morreu ????737383$;@9¥&amp;@(849($4@;89...           1   \n",
       "41  *sylvie e loki sentados em um banco*\\n\\nravonn...           0   \n",
       "42  @anderson839517 @nacaomarvei como assim?? \\nel...           0   \n",
       "43                        a serie do loki e muito boa           1   \n",
       "44  @mobiusdaavt @torystyliinson @loki_l4ufeys0n é...           0   \n",
       "45  que vergonha dizer isto agora, porque já devia...           0   \n",
       "46  gente, a sylvie e o loki não são a mesma pesso...           0   \n",
       "47  obra de @moopzies \\n\\n#marvel #loki https://t....           0   \n",
       "48  @cnn, aqui, até loki seleciona mídia de qualid...           0   \n",
       "49  eu na minha analise do loki https://t.co/lcglw...           1   \n",
       "\n",
       "                                                Clean  Modelo           Prob  \\\n",
       "0                              demor final assist lok       1   6.215533e-11   \n",
       "1                 xiu nao quer sab voc import lok viv       0  -6.985989e-20   \n",
       "2                          tia sylvi atorment tio lok       1   6.706150e-15   \n",
       "3                vot 24 eleg lok president 2022 brilh       0  -1.214690e-23   \n",
       "4                                   indo desc lok mim       1  -5.390588e-11   \n",
       "5   nao consig escolh amo tod vdd amo lok thor 1 d...       1   3.599347e-36   \n",
       "6   teor interess muit possivel acontec mesm nao s...       0  -1.712304e-25   \n",
       "7                                           abutr lok       1  -1.504878e-06   \n",
       "8                                        mand fot lok       0  -1.581796e-06   \n",
       "9   togeth all tim sylki au dois lok linh temp pro...       1  4.655229e-100   \n",
       "10            100 00 ode16jdb1p confirmed maosparacim       1  -9.077626e-17   \n",
       "11  primeir otar sort segund tud mund sab melhor s...       1   2.858960e-32   \n",
       "12                  ta faz almoc depo voc vir my lady       0  -2.869879e-20   \n",
       "13                 lok aparec rostosorridentecomchifr       1   6.564786e-09   \n",
       "14  seri horrivel perd temp kkkk aind nao dei trab...       1   3.136772e-30   \n",
       "15      sindrom total desvaloriz car lok antagon vila       1  -1.394979e-24   \n",
       "16                                    mem variant lok       1  -7.406531e-08   \n",
       "17  hoj vou comec lok continu ratched marcadeselec...       1  -2.734735e-20   \n",
       "18                                      lind redheart       0  -3.480045e-07   \n",
       "19  lok premiss utiliz long seri otim element just...       1   1.420468e-53   \n",
       "20  cert trat variant lok tom cont brasil variant ...       0   5.983838e-35   \n",
       "21                        li lok disfarc zec pagodinh       1  -1.466209e-15   \n",
       "22         irma discut lok menin menin fez dia kkkkkk       0   3.056563e-23   \n",
       "23          lok mt ensin histor carmen dia antes prov       1   1.355732e-23   \n",
       "24                          lok nao acord log bem mal       0  -3.085020e-15   \n",
       "25  segund amig gost p hom eh mt previsivel tod sa...       1  -7.364123e-44   \n",
       "26                                peg dois faz trisal       0  -1.975575e-12   \n",
       "27  aceit quadrisal rostocomamaosobreaboc rostocom...       0  -7.303479e-13   \n",
       "28            allor fat incontrar thor lok vi denunci       1  -3.000875e-21   \n",
       "29  vou cas dorm descans impecilh lok surt quer brinc       0  -1.520047e-25   \n",
       "30                     cuid nao cair rostocomolhopisc       0  -2.048838e-11   \n",
       "31                       lok vai lut contr nikol tesl       0  -9.519391e-17   \n",
       "32                                  quer funk lok aff       1   3.167916e-11   \n",
       "33                                        lok perfeit       1   4.811239e-06   \n",
       "34                                         voc entreg       1  -1.095780e-06   \n",
       "35              yt dev ta bug man seman pass tav muit       0  -3.346048e-23   \n",
       "36  nfa tim pipoc sempr cop nobru don org vcs pass...       0  -4.010089e-59   \n",
       "37  eit lok vai ta mesm tim gent vou pod continu d...       0  -9.352945e-34   \n",
       "38                                          fodas lok       1   6.273745e-06   \n",
       "39  ment porqu 2018 lok diss porc sol ia brilh por...       1   1.959366e-90   \n",
       "40                  lok morr 737383 amp 849 4 894 amp       1   2.689205e-24   \n",
       "41  sylvi lok sent banc ravonn ue vcs parec tao tr...       1  -1.377022e-67   \n",
       "42  assim so surg depo vingador tinh derrot lok ul...       0  -2.272071e-66   \n",
       "43                                  seri lok muit boa       1   5.966817e-10   \n",
       "44                                      clar amorzinh       0  -2.253011e-06   \n",
       "45  vergonh diz agor porqu dev ter vist ha bue fin...       1   2.233481e-44   \n",
       "46  gent sylvi lok nao sao mesm pesso imagin vcs e...       1  -1.500161e-93   \n",
       "47                                               obra       1  -1.609808e-04   \n",
       "48  aqu ate lok selecion mid qualidad par acompanh...       1   8.392892e-35   \n",
       "49                                    minh analis lok       0  -3.423858e-08   \n",
       "\n",
       "   Grau de Relevancia  \n",
       "0     Muito Relevante  \n",
       "1         Irrelevante  \n",
       "2     Muito Relevante  \n",
       "3         Irrelevante  \n",
       "4   Muito Irrelevante  \n",
       "5           Relevante  \n",
       "6         Irrelevante  \n",
       "7   Muito Irrelevante  \n",
       "8   Muito Irrelevante  \n",
       "9              Neutro  \n",
       "10  Muito Irrelevante  \n",
       "11          Relevante  \n",
       "12        Irrelevante  \n",
       "13    Muito Relevante  \n",
       "14          Relevante  \n",
       "15        Irrelevante  \n",
       "16  Muito Irrelevante  \n",
       "17        Irrelevante  \n",
       "18  Muito Irrelevante  \n",
       "19             Neutro  \n",
       "20          Relevante  \n",
       "21  Muito Irrelevante  \n",
       "22          Relevante  \n",
       "23          Relevante  \n",
       "24  Muito Irrelevante  \n",
       "25        Irrelevante  \n",
       "26  Muito Irrelevante  \n",
       "27  Muito Irrelevante  \n",
       "28        Irrelevante  \n",
       "29        Irrelevante  \n",
       "30  Muito Irrelevante  \n",
       "31  Muito Irrelevante  \n",
       "32    Muito Relevante  \n",
       "33    Muito Relevante  \n",
       "34  Muito Irrelevante  \n",
       "35        Irrelevante  \n",
       "36        Irrelevante  \n",
       "37        Irrelevante  \n",
       "38    Muito Relevante  \n",
       "39             Neutro  \n",
       "40          Relevante  \n",
       "41             Neutro  \n",
       "42             Neutro  \n",
       "43    Muito Relevante  \n",
       "44  Muito Irrelevante  \n",
       "45             Neutro  \n",
       "46             Neutro  \n",
       "47  Muito Irrelevante  \n",
       "48          Relevante  \n",
       "49  Muito Irrelevante  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "test_degree['Grau de Relevancia']= test_degree.Prob.apply(Categories)\n",
    "# test_categorie_degree=test_categorie_degree.drop('Prob',axis=1)\n",
    "test_degree.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* (x) IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords \n",
    "\n",
    "* (x) CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis \n",
    "\n",
    "* (x) CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado) --------\n",
    "\n",
    "* (x) EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento (x)\n",
    "\n",
    "* (x) PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (x)\n",
    "\n",
    "* (x) SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa) \n",
    "\n",
    "* (x) FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "\n",
    "* [A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "\n",
    "* [The application of naive Bayes model averaging to predict Alzheimer's disease from genome-wide data](https://academic.oup.com/jamia/article/18/4/370/732731?login=true)\n",
    "\n",
    "\n",
    "* [A Novel Application of Naive Bayes Classifier in Photovoltaic Energy Prediction](https://ieeexplore.ieee.org/abstract/document/8260684)\n",
    "\n",
    "\n",
    "* [Spam/ham detection using Naive bayes Classifier](https://www.kaggle.com/dilip990/spam-ham-detection-using-naive-bayes-classifier)\n",
    "\n",
    "\n",
    "* [Week 6 - Language - CS50 - Introduction to Artificial Inteligence with Python - HarvardX](https://cs50.harvard.edu/ai/2020/notes/6/)\n",
    "\n",
    "\n",
    "* Vlado Keˇselj, Fuchun Peng, Nick Cercone, and Calvin Thomas. N-grambased author profiles for authorship attribution. In Proceedings of the conference pacific association for computational linguistics, PACLING, volume 3, pages 255–264, 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
