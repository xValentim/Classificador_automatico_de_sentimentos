{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: João Gabriel Valentim Rocha\n",
    "\n",
    "Nome: Enzo Dadier Lacks Zamberlan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\gabri\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from seaborn) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (7.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.5.0.tar.gz (185 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.5.0-py3-none-any.whl size=187447 sha256=27aa3dbc73cb8d6664c0b6f79daa5b81c789451d7496485d1ca0db2f7db91bbc\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\e9\\d5\\46\\33c9101a710eb267fbaf8572c96fce5b12702e62bb5fa40592\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-1.5.0\n",
      "Collecting pysinonimos\n",
      "  Downloading pysinonimos-0.1.1.tar.gz (2.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pysinonimos) (2.24.0)\n",
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.5.0-py2.py3-none-any.whl (254 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->pysinonimos) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->pysinonimos) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->pysinonimos) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->pysinonimos) (3.0.4)\n",
      "Collecting parsel>=1.5.0\n",
      "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting queuelib>=1.4.2\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=16.0.0\n",
      "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Downloading itemadapter-0.4.0-py3-none-any.whl (10 kB)\n",
      "Collecting PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\"\n",
      "  Downloading PyDispatcher-2.0.5.tar.gz (34 kB)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scrapy->pysinonimos) (5.1.2)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scrapy->pysinonimos) (3.1.1)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scrapy->pysinonimos) (19.1.0)\n",
      "Collecting Twisted[http2]>=17.9.0\n",
      "  Downloading Twisted-21.7.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting protego>=0.1.15\n",
      "  Downloading Protego-0.1.16.tar.gz (3.2 MB)\n",
      "Collecting h2<4.0,>=3.0\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Downloading itemloaders-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scrapy->pysinonimos) (4.6.1)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: six>=1.6.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from parsel>=1.5.0->scrapy->pysinonimos) (1.15.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->pysinonimos) (0.4.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->pysinonimos) (20.3.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->pysinonimos) (0.2.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from zope.interface>=4.1.3->scrapy->pysinonimos) (50.3.1.post20201107)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy->pysinonimos) (1.14.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy->pysinonimos) (3.7.4.3)\n",
      "Collecting incremental>=21.3.0\n",
      "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting twisted-iocpsupport~=1.0.0; platform_system == \"Windows\"\n",
      "  Downloading twisted_iocpsupport-1.0.2-cp38-cp38-win_amd64.whl (45 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Collecting Automat>=0.8.0\n",
      "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting constantly>=15.1\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting priority<2.0,>=1.1.0; extra == \"http2\"\n",
      "  Downloading priority-1.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy->pysinonimos) (2.20)\n",
      "Building wheels for collected packages: pysinonimos, PyDispatcher, protego\n",
      "  Building wheel for pysinonimos (setup.py): started\n",
      "  Building wheel for pysinonimos (setup.py): finished with status 'done'\n",
      "  Created wheel for pysinonimos: filename=pysinonimos-0.1.1-py3-none-any.whl size=2458 sha256=aea325f593ed2b893c015dcfc5a2445575e1057d512f015876836ee199513126\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\52\\3b\\eb\\f40f66159b8c2a9b9b25c4e1f91ff7f566b7f2305268adf062\n",
      "  Building wheel for PyDispatcher (setup.py): started\n",
      "  Building wheel for PyDispatcher (setup.py): finished with status 'done'\n",
      "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-py3-none-any.whl size=12552 sha256=51d9858864eb605c304b359b55d897e22242f36e2ecd7c7dd08434a2da29b6bb\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\d1\\d7\\61\\11b5b370ee487d38b5408ecb7e0257db9107fa622412cbe2ff\n",
      "  Building wheel for protego (setup.py): started\n",
      "  Building wheel for protego (setup.py): finished with status 'done'\n",
      "  Created wheel for protego: filename=Protego-0.1.16-py3-none-any.whl size=7770 sha256=100548b250ffa97a0ec2a3a995a3db5714608dec9d98416b297e053e497ee55d\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\91\\64\\36\\bd0d11306cb22a78c7f53d603c7eb74ebb6c211703bc40b686\n",
      "Successfully built pysinonimos PyDispatcher protego\n",
      "Installing collected packages: w3lib, cssselect, parsel, queuelib, service-identity, itemadapter, PyDispatcher, incremental, twisted-iocpsupport, hyperlink, Automat, constantly, priority, hpack, hyperframe, h2, Twisted, protego, jmespath, itemloaders, scrapy, pysinonimos\n",
      "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Twisted-21.7.0 constantly-15.1.0 cssselect-1.1.0 h2-3.2.0 hpack-3.0.0 hyperframe-5.2.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.4.0 itemloaders-1.0.4 jmespath-0.10.0 parsel-1.6.0 priority-1.3.0 protego-0.1.16 pysinonimos-0.1.1 queuelib-1.6.2 scrapy-2.5.0 service-identity-21.1.0 twisted-iocpsupport-1.0.2 w3lib-1.22.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gabri\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: regex in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: sklearn in c:\\users\\gabri\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install emoji\n",
    "!pip install pysinonimos\n",
    "!pip install nltk\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import nltk\n",
    "import pysinonimos.sinonimos as sinom\n",
    "from emoji import UNICODE_EMOJI\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\gabri\\Desktop\\Matérias 2 semestre\\cdados\\P1\\Classificador_automatico_de_sentimentos\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'assets/loki.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mood de hj: bolsominion veio falar com loki:\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdds do loki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>considerações finais de loki: parabéns marvel,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_namizinhaa @yaluv_ @_girlrainbow versão femi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o loki merece todo o amor do mundo ? \\n \\n  si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>o loki tbm ? percebi que nao sei mais nada sob...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tô desde as 9 fazendo atividade e o loki destr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@torystyliinson @mobiusdaavt pede pra ele te m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>bolsonaro tá desesperado. discurso inflado, go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>vou terminar loki hj, espero não me decepcionar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia\n",
       "0    mood de hj: bolsominion veio falar com loki:\\n...           0\n",
       "1                                         sdds do loki           1\n",
       "2    considerações finais de loki: parabéns marvel,...           1\n",
       "3    @_namizinhaa @yaluv_ @_girlrainbow versão femi...           0\n",
       "4    o loki merece todo o amor do mundo ? \\n \\n  si...           1\n",
       "..                                                 ...         ...\n",
       "295  o loki tbm ? percebi que nao sei mais nada sob...           1\n",
       "296  tô desde as 9 fazendo atividade e o loki destr...           0\n",
       "297  @torystyliinson @mobiusdaavt pede pra ele te m...           0\n",
       "298  bolsonaro tá desesperado. discurso inflado, go...           0\n",
       "299    vou terminar loki hj, espero não me decepcionar           1\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comecei loki e logo no primeiro episódio ele s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@thylaspirk exatamente \\nnão dá cara loki mere...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pq a marvel falou que loki é irmão se thor sen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vou fazer com o loki 🥰🤣 https://t.co/qry6pytktj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@stawocon loki eu ainda vi dnv ksksksksksksksk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  comecei loki e logo no primeiro episódio ele s...           1\n",
       "1  @thylaspirk exatamente \\nnão dá cara loki mere...           1\n",
       "2  pq a marvel falou que loki é irmão se thor sen...           0\n",
       "3    vou fazer com o loki 🥰🤣 https://t.co/qry6pytktj           1\n",
       "4  @stawocon loki eu ainda vi dnv ksksksksksksksk...           1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O classificador automático de sentimentos montado tem como critério utilizado a relevância de tweets que remetam a alguma reação ou laço sentimental em relação à série, sendo os mesmos positivos ou não (elogiando algum episódio, comentando valores da série, ou ainda, criticando os mesmos). Neste sentido, postagens que dizem respeito unicamente a aspectos nesse tocante, elogiando ou comentando sobre os atores da obra, como também tweets com vagas menções sobre a série, foram considerados como irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimentos e configurações iniciais\n",
    "\n",
    "Para continuarmos, é necessário definir algumas funções básicas que vão nos ajudar:\n",
    "\n",
    "1) Primeiro, vamos fazer a limpeza dos tweets. Retirando simbolos e pontuações que não serão contabilizadas para nossa análise\n",
    "\n",
    "2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1\n",
    "def limpa_frase(frase):\n",
    "    # Primeiro, poe todas as palavras com letras minúsculas\n",
    "    aux = frase.lower()\n",
    "    \n",
    "    # Segundo, remove # and @\n",
    "    aux = re.sub(\"@[A-Za-z0-9_]+\",\"\", aux)\n",
    "    aux = re.sub(\"#[A-Za-z0-9_]+\",\"\", aux)\n",
    "    \n",
    "    # Terceiro, remove links\n",
    "    aux = re.sub(r\"http\\S+\", \"\", aux)\n",
    "    aux = re.sub(r\"www.\\S+\", \"\", aux)\n",
    "    \n",
    "    # Quarto, remove pontuação\n",
    "    aux = re.sub('[()!?]', ' ', aux)\n",
    "    aux = re.sub('\\[.*?\\]',' ', aux)\n",
    "    \n",
    "    # Quinto, remove acentos\n",
    "    #aux = unidecode.unidecode(aux)\n",
    "    \n",
    "    # Sexto, remove não alfa-numericos\n",
    "    #aux = re.sub(\"[^a-z0-9]\",\" \", aux)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2\n",
    "def tokenize(frase):\n",
    "    return frase.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Passo 3 \n",
    "nltk.download('stopwords')\n",
    "prep = nltk.corpus.stopwords.words('portuguese')\n",
    "prep.append('')\n",
    "prep = prep + ['n', 's']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4\n",
    "def no_stop_words(token):\n",
    "    clear = []\n",
    "    for element in token:\n",
    "        if element not in prep:\n",
    "            clear.append(element)\n",
    "    return clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_1 = test['Teste'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vou', 'fazer', 'loki', '🥰🤣']\n"
     ]
    }
   ],
   "source": [
    "print(no_stop_words(tokenize(limpa_frase(frase_1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
