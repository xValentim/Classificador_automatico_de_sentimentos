{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Jo√£o Gabriel Valentim Rocha\n",
    "\n",
    "Nome: Enzo Dadier Lacks Zamberlan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\gabri\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from seaborn) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (7.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.5.0.tar.gz (185 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.5.0-py3-none-any.whl size=187447 sha256=27aa3dbc73cb8d6664c0b6f79daa5b81c789451d7496485d1ca0db2f7db91bbc\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\e9\\d5\\46\\33c9101a710eb267fbaf8572c96fce5b12702e62bb5fa40592\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-1.5.0\n",
      "Collecting pysinonimos\n",
      "  Downloading pysinonimos-0.1.1.tar.gz (2.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pysinonimos) (2.24.0)\n",
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.5.0-py2.py3-none-any.whl (254 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->pysinonimos) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->pysinonimos) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->pysinonimos) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->pysinonimos) (3.0.4)\n",
      "Collecting parsel>=1.5.0\n",
      "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting queuelib>=1.4.2\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=16.0.0\n",
      "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Downloading itemadapter-0.4.0-py3-none-any.whl (10 kB)\n",
      "Collecting PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\"\n",
      "  Downloading PyDispatcher-2.0.5.tar.gz (34 kB)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scrapy->pysinonimos) (5.1.2)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scrapy->pysinonimos) (3.1.1)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scrapy->pysinonimos) (19.1.0)\n",
      "Collecting Twisted[http2]>=17.9.0\n",
      "  Downloading Twisted-21.7.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting protego>=0.1.15\n",
      "  Downloading Protego-0.1.16.tar.gz (3.2 MB)\n",
      "Collecting h2<4.0,>=3.0\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Downloading itemloaders-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scrapy->pysinonimos) (4.6.1)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: six>=1.6.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from parsel>=1.5.0->scrapy->pysinonimos) (1.15.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->pysinonimos) (0.4.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->pysinonimos) (20.3.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->pysinonimos) (0.2.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from zope.interface>=4.1.3->scrapy->pysinonimos) (50.3.1.post20201107)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy->pysinonimos) (1.14.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy->pysinonimos) (3.7.4.3)\n",
      "Collecting incremental>=21.3.0\n",
      "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting twisted-iocpsupport~=1.0.0; platform_system == \"Windows\"\n",
      "  Downloading twisted_iocpsupport-1.0.2-cp38-cp38-win_amd64.whl (45 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Collecting Automat>=0.8.0\n",
      "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting constantly>=15.1\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting priority<2.0,>=1.1.0; extra == \"http2\"\n",
      "  Downloading priority-1.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy->pysinonimos) (2.20)\n",
      "Building wheels for collected packages: pysinonimos, PyDispatcher, protego\n",
      "  Building wheel for pysinonimos (setup.py): started\n",
      "  Building wheel for pysinonimos (setup.py): finished with status 'done'\n",
      "  Created wheel for pysinonimos: filename=pysinonimos-0.1.1-py3-none-any.whl size=2458 sha256=aea325f593ed2b893c015dcfc5a2445575e1057d512f015876836ee199513126\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\52\\3b\\eb\\f40f66159b8c2a9b9b25c4e1f91ff7f566b7f2305268adf062\n",
      "  Building wheel for PyDispatcher (setup.py): started\n",
      "  Building wheel for PyDispatcher (setup.py): finished with status 'done'\n",
      "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-py3-none-any.whl size=12552 sha256=51d9858864eb605c304b359b55d897e22242f36e2ecd7c7dd08434a2da29b6bb\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\d1\\d7\\61\\11b5b370ee487d38b5408ecb7e0257db9107fa622412cbe2ff\n",
      "  Building wheel for protego (setup.py): started\n",
      "  Building wheel for protego (setup.py): finished with status 'done'\n",
      "  Created wheel for protego: filename=Protego-0.1.16-py3-none-any.whl size=7770 sha256=100548b250ffa97a0ec2a3a995a3db5714608dec9d98416b297e053e497ee55d\n",
      "  Stored in directory: c:\\users\\gabri\\appdata\\local\\pip\\cache\\wheels\\91\\64\\36\\bd0d11306cb22a78c7f53d603c7eb74ebb6c211703bc40b686\n",
      "Successfully built pysinonimos PyDispatcher protego\n",
      "Installing collected packages: w3lib, cssselect, parsel, queuelib, service-identity, itemadapter, PyDispatcher, incremental, twisted-iocpsupport, hyperlink, Automat, constantly, priority, hpack, hyperframe, h2, Twisted, protego, jmespath, itemloaders, scrapy, pysinonimos\n",
      "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Twisted-21.7.0 constantly-15.1.0 cssselect-1.1.0 h2-3.2.0 hpack-3.0.0 hyperframe-5.2.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.4.0 itemloaders-1.0.4 jmespath-0.10.0 parsel-1.6.0 priority-1.3.0 protego-0.1.16 pysinonimos-0.1.1 queuelib-1.6.2 scrapy-2.5.0 service-identity-21.1.0 twisted-iocpsupport-1.0.2 w3lib-1.22.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gabri\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: regex in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: sklearn in c:\\users\\gabri\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install emoji\n",
    "!pip install pysinonimos\n",
    "!pip install nltk\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import nltk\n",
    "import pysinonimos.sinonimos as sinom\n",
    "from emoji import UNICODE_EMOJI\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\gabri\\Desktop\\Mat√©rias 2 semestre\\cdados\\P1\\Classificador_automatico_de_sentimentos\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'assets/loki.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mood de hj: bolsominion veio falar com loki:\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdds do loki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>considera√ß√µes finais de loki: parab√©ns marvel,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_namizinhaa @yaluv_ @_girlrainbow vers√£o femi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o loki merece todo o amor do mundo ? \\n \\n  si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>o loki tbm ? percebi que nao sei mais nada sob...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>t√¥ desde as 9 fazendo atividade e o loki destr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@torystyliinson @mobiusdaavt pede pra ele te m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>bolsonaro t√° desesperado. discurso inflado, go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>vou terminar loki hj, espero n√£o me decepcionar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevancia\n",
       "0    mood de hj: bolsominion veio falar com loki:\\n...           0\n",
       "1                                         sdds do loki           1\n",
       "2    considera√ß√µes finais de loki: parab√©ns marvel,...           1\n",
       "3    @_namizinhaa @yaluv_ @_girlrainbow vers√£o femi...           0\n",
       "4    o loki merece todo o amor do mundo ? \\n \\n  si...           1\n",
       "..                                                 ...         ...\n",
       "295  o loki tbm ? percebi que nao sei mais nada sob...           1\n",
       "296  t√¥ desde as 9 fazendo atividade e o loki destr...           0\n",
       "297  @torystyliinson @mobiusdaavt pede pra ele te m...           0\n",
       "298  bolsonaro t√° desesperado. discurso inflado, go...           0\n",
       "299    vou terminar loki hj, espero n√£o me decepcionar           1\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comecei loki e logo no primeiro epis√≥dio ele s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@thylaspirk exatamente \\nn√£o d√° cara loki mere...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pq a marvel falou que loki √© irm√£o se thor sen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vou fazer com o loki ü•∞ü§£ https://t.co/qry6pytktj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@stawocon loki eu ainda vi dnv ksksksksksksksk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>vou fazer uma x√≠cara tem√°tica pra mim, mas t√¥ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>o primeiro dente de leite de loki caiu https:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>@mobiusdaavt @loki_l4ufeys0n eu vou te bloquear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>queria ter juntado uma semana de merda de loki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>como a po$$@ de um tanque de guerra de cerveja...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevancia\n",
       "0    comecei loki e logo no primeiro epis√≥dio ele s...           1\n",
       "1    @thylaspirk exatamente \\nn√£o d√° cara loki mere...           1\n",
       "2    pq a marvel falou que loki √© irm√£o se thor sen...           0\n",
       "3      vou fazer com o loki ü•∞ü§£ https://t.co/qry6pytktj           1\n",
       "4    @stawocon loki eu ainda vi dnv ksksksksksksksk...           1\n",
       "..                                                 ...         ...\n",
       "195  vou fazer uma x√≠cara tem√°tica pra mim, mas t√¥ ...           0\n",
       "196  o primeiro dente de leite de loki caiu https:/...           0\n",
       "197    @mobiusdaavt @loki_l4ufeys0n eu vou te bloquear           0\n",
       "198  queria ter juntado uma semana de merda de loki...           0\n",
       "199  como a po$$@ de um tanque de guerra de cerveja...           0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O classificador autom√°tico de sentimentos montado tem como crit√©rio utilizado a relev√¢ncia de tweets que remetam a alguma rea√ß√£o ou la√ßo sentimental em rela√ß√£o √† s√©rie, sendo os mesmos positivos ou n√£o (elogiando algum epis√≥dio, comentando valores da s√©rie, ou ainda, criticando os mesmos). Neste sentido, postagens que dizem respeito unicamente a aspectos nesse tocante, elogiando ou comentando sobre os atores da obra, como tamb√©m tweets com vagas men√ß√µes sobre a s√©rie, foram considerados como irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimentos e configura√ß√µes iniciais\n",
    "\n",
    "Para continuarmos, √© necess√°rio definir algumas fun√ß√µes b√°sicas que v√£o nos ajudar:\n",
    "\n",
    "1) Primeiro, vamos fazer a limpeza dos tweets. Retirando simbolos e pontua√ß√µes que n√£o ser√£o contabilizadas para nossa an√°lise\n",
    "\n",
    "2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 0 - Defini√ß√£o de transcri√ß√£o de emojis\n",
    "def separa_emoji(tweet):\n",
    "    '''\n",
    "    Essa fun√ß√£o separa os emojis juntos, al√©m de transcreve-los\n",
    "    para suas respectivas strings descritivas, optimizando um pouco o processamento.\n",
    "    Nota-se que alguns emojis n√£o usados n√£o est√£o no Unicode da l√≠ngua portuguesa,\n",
    "    adotamos assim o de l√≠ngua inglesa como alternativa de transcri√ß√£o.\n",
    "    '''\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\n",
    "    modified=modified.split()\n",
    "    for i,emoji1 in enumerate(modified):\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\n",
    "        else:\n",
    "            continue\n",
    "    modified=' '.join(modified)\n",
    "        \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1\n",
    "def limpa_frase(frase):\n",
    "    # Primeiro, poe todas as palavras com letras min√∫sculas\n",
    "    aux = frase.lower()\n",
    "    \n",
    "    # Segundo, remove # and @\n",
    "    aux = re.sub(\"@[A-Za-z0-9_]+\",\"\", aux)\n",
    "    aux = re.sub(\"#[A-Za-z0-9_]+\",\"\", aux)\n",
    "    \n",
    "    # Terceiro, remove links\n",
    "    aux = re.sub(r\"http\\S+\", \"\", aux)\n",
    "    aux = re.sub(r\"www.\\S+\", \"\", aux)\n",
    "    \n",
    "    # Quarto, remove pontua√ß√£o\n",
    "    aux = re.sub('[()!?]', ' ', aux)\n",
    "    aux = re.sub('\\[.*?\\]',' ', aux)\n",
    "    \n",
    "    #\n",
    "    aux = separa_emoji(aux)\n",
    "    \n",
    "    aux = aux.replace(\"_\", \"\")\n",
    "    \n",
    "    # Quinto, remove acentos\n",
    "    aux = unidecode.unidecode(aux)\n",
    "    \n",
    "    # Sexto, remove n√£o alfa-numericos\n",
    "    # ---------------rever--------------\n",
    "    aux = re.sub(\"[^a-z0-9]\",\" \", aux)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2\n",
    "def tokenize(frase):\n",
    "    return frase.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Passo 3 \n",
    "nltk.download('stopwords')\n",
    "prep = nltk.corpus.stopwords.words('portuguese')\n",
    "prep.append('')\n",
    "prep = prep + ['n', 's']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4\n",
    "def no_stop_words(token):\n",
    "    clear = []\n",
    "    for element in token:\n",
    "        if element not in prep:\n",
    "            clear.append(element)\n",
    "    return clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(lista):\n",
    "    return ' '.join(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_tweet(tweet):\n",
    "    return list_to_string(no_stop_words(tokenize(limpa_frase(tweet))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frases_to_series(frases):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_1 = test['Teste'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vou', 'fazer', 'loki', 'rostosorridentecom3coracoes', 'rolandonochaoderir']\n",
      "vou fazer loki rostosorridentecom3coracoes rolandonochaoderir\n"
     ]
    }
   ],
   "source": [
    "print(no_stop_words(tokenize(limpa_frase(frase_1))))\n",
    "frase_2 = list_to_string(no_stop_words(tokenize(limpa_frase(frase_1))))\n",
    "print(frase_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vou fazer loki rostosorridentecom3coracoes rolandonochaoderir\n"
     ]
    }
   ],
   "source": [
    "print(separa_emoji(frase_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vou fazer loki rostosorridentecom3coracoes rolandonochaoderir\n"
     ]
    }
   ],
   "source": [
    "print(limpa_tweet(frase_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['consideracoes', 'finais', 'loki', 'parabens', 'marvel', 'chorei', 'igual', 'vagabunda', 'shipp', 'q', 'claramente', 'nao', 'endgame', 'matei', 'resto', 'neuronios', 'mt', 'bom', 'nota', '10']\n"
     ]
    }
   ],
   "source": [
    "frase_3 = train['Treinamento'][2]\n",
    "print(no_stop_words(tokenize(limpa_frase(frase_3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando palavras em vari√°veis categ√≥ricas:\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando fun√ß√µes de limpeza e certifica√ß√£o no dataframe de treinamento da base de dados:\n",
    "train['Clean']=train['Treinamento'].apply(limpa_tweet)\n",
    "test['Clean']=test['Teste'].apply(limpa_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rel = train.loc[train['Relevancia'] == 1, :]\n",
    "train_irrel= train.loc[train['Relevancia'] == 0, :]\n",
    "\n",
    "palavras_rel = []\n",
    "palavras_irrel = []\n",
    "for i in range(len(train['Treinamento'])):\n",
    "    if train['Relevancia'][i] == 1:\n",
    "        tweet = train['Treinamento'][i]\n",
    "        tweet = tokenize(limpa_tweet(tweet))\n",
    "        palavras_rel += tweet\n",
    "    else:\n",
    "        tweet = train['Treinamento'][i]\n",
    "        tweet = tokenize(limpa_tweet(tweet))\n",
    "        palavras_irrel += tweet\n",
    "        \n",
    "palavras_rel = pd.Series(palavras_rel)\n",
    "palavras_irrel = pd.Series(palavras_irrel)\n",
    "aux = list(palavras_irrel) + list(palavras_rel)\n",
    "palavras_totais = pd.Series(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loki                      0.109391\n",
       "rostochorandoaosberros    0.019608\n",
       "nao                       0.019608\n",
       "thor                      0.015480\n",
       "serie                     0.013416\n",
       "                            ...   \n",
       "riverdale                 0.001032\n",
       "crime                     0.001032\n",
       "terca                     0.001032\n",
       "d                         0.001032\n",
       "enganar                   0.001032\n",
       "Length: 547, dtype: float64"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequencias relativas\n",
    "freq_rel_relevantes = palavras_rel.value_counts(True)\n",
    "freq_rel_irrelevantes = palavras_irrel.value_counts(True)\n",
    "freq_rel_total = palavras_totais.value_counts(True)\n",
    "freq_rel_relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dou' in freq_rel_irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com as palavras relevantes e irrelevantes\n",
    "lista_rel = palavras_rel.to_list()\n",
    "lista_irrel = palavras_irrel.to_list()\n",
    "\n",
    "# Todas as palavras possiveis\n",
    "todas_as_palavras = list(set(lista_rel + lista_irrel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidades \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note que P_R (probabilidade de ser relevante) e P_Rc (probabilidade de ser irrelevante) s√£o complementares!\n",
    "P_R = len(palavras_rel) / (len(palavras_rel) + len(palavras_irrel))\n",
    "P_Rc = 1 - P_R\n",
    "'dou' in lista_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comecei loki e logo no primeiro epis√≥dio ele s...</td>\n",
       "      <td>1</td>\n",
       "      <td>comecei loki logo primeiro episodio camisa obg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@thylaspirk exatamente \\nn√£o d√° cara loki mere...</td>\n",
       "      <td>1</td>\n",
       "      <td>exatamente nao cara loki merecia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pq a marvel falou que loki √© irm√£o se thor sen...</td>\n",
       "      <td>0</td>\n",
       "      <td>pq marvel falou loki irmao thor sendo q irmao ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vou fazer com o loki ü•∞ü§£ https://t.co/qry6pytktj</td>\n",
       "      <td>1</td>\n",
       "      <td>vou fazer loki rostosorridentecom3coracoes rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@stawocon loki eu ainda vi dnv ksksksksksksksk...</td>\n",
       "      <td>1</td>\n",
       "      <td>loki ainda vi dnv ksksksksksksksksk agora what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>vou fazer uma x√≠cara tem√°tica pra mim, mas t√¥ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>vou fazer xicara tematica pra mim to duvida fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>o primeiro dente de leite de loki caiu https:/...</td>\n",
       "      <td>0</td>\n",
       "      <td>primeiro dente leite loki caiu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>@mobiusdaavt @loki_l4ufeys0n eu vou te bloquear</td>\n",
       "      <td>0</td>\n",
       "      <td>vou bloquear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>queria ter juntado uma semana de merda de loki...</td>\n",
       "      <td>0</td>\n",
       "      <td>queria ter juntado semana merda loki pra jogar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>como a po$$@ de um tanque de guerra de cerveja...</td>\n",
       "      <td>0</td>\n",
       "      <td>po tanque guerra cerveja pede paz tanque guerr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevancia  \\\n",
       "0    comecei loki e logo no primeiro epis√≥dio ele s...           1   \n",
       "1    @thylaspirk exatamente \\nn√£o d√° cara loki mere...           1   \n",
       "2    pq a marvel falou que loki √© irm√£o se thor sen...           0   \n",
       "3      vou fazer com o loki ü•∞ü§£ https://t.co/qry6pytktj           1   \n",
       "4    @stawocon loki eu ainda vi dnv ksksksksksksksk...           1   \n",
       "..                                                 ...         ...   \n",
       "195  vou fazer uma x√≠cara tem√°tica pra mim, mas t√¥ ...           0   \n",
       "196  o primeiro dente de leite de loki caiu https:/...           0   \n",
       "197    @mobiusdaavt @loki_l4ufeys0n eu vou te bloquear           0   \n",
       "198  queria ter juntado uma semana de merda de loki...           0   \n",
       "199  como a po$$@ de um tanque de guerra de cerveja...           0   \n",
       "\n",
       "                                                 Clean  \n",
       "0    comecei loki logo primeiro episodio camisa obg...  \n",
       "1                     exatamente nao cara loki merecia  \n",
       "2    pq marvel falou loki irmao thor sendo q irmao ...  \n",
       "3    vou fazer loki rostosorridentecom3coracoes rol...  \n",
       "4    loki ainda vi dnv ksksksksksksksksk agora what...  \n",
       "..                                                 ...  \n",
       "195  vou fazer xicara tematica pra mim to duvida fa...  \n",
       "196                     primeiro dente leite loki caiu  \n",
       "197                                       vou bloquear  \n",
       "198  queria ter juntado semana merda loki pra jogar...  \n",
       "199  po tanque guerra cerveja pede paz tanque guerr...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidadeCD (frase, arg):\n",
    "    if arg == 'R':\n",
    "        probFraseDadoR = 1\n",
    "        for palavra in frase:\n",
    "            try:\n",
    "                probFraseDadoR *= freq_rel_relevantes[palavra]\n",
    "            except:\n",
    "                try:\n",
    "                    probFraseDadoR *= freq_rel_total[palavra]\n",
    "                except:\n",
    "                    continue\n",
    "        return probFraseDadoR\n",
    "    if arg == 'I':\n",
    "        probFraseDadoI = 1\n",
    "        for palavra in frase:\n",
    "            try:\n",
    "                probFraseDadoI *= freq_rel_irrelevantes[palavra]\n",
    "            except:\n",
    "                try:\n",
    "                    probFraseDadoI *= freq_rel_total[palavra]\n",
    "                except:\n",
    "                    continue\n",
    "        return probFraseDadoI\n",
    "i = 160\n",
    "frase_1 = list(tokenize(train['Clean'][i]))\n",
    "frase_1\n",
    "probFraseDadoR, probFraseDadoI = probabilidadeCD(frase_1, 'R'), probabilidadeCD(frase_1, 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentual de acerto:  0.565\n"
     ]
    }
   ],
   "source": [
    "# Comparativo: \n",
    "acertos = 0\n",
    "for i in range(len(test) - 1):\n",
    "    frase_1 = list(tokenize(test['Clean'][i]))\n",
    "    probFraseDadoR, probFraseDadoI = probabilidadeCD(frase_1, 'R'), probabilidadeCD(frase_1, 'I')\n",
    "    probRdadoFrase = probFraseDadoR * P_R\n",
    "    probIdadoFrase = probFraseDadoI * P_Rc\n",
    "    if probRdadoFrase > probIdadoFrase:\n",
    "        relevancia_prevista = 1\n",
    "    else:\n",
    "        relevancia_prevista = 0\n",
    "    if relevancia_prevista == test['Relevancia'][i]:\n",
    "        acertos += 1\n",
    "    #print(i, relevancia_prevista, test['Relevancia'][i])\n",
    "print('percentual de acerto: ', acertos / len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
